{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "© 2025 Vanargo · Лицензия: MIT. См. файл `LICENSE` в корне репозитория."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# --- Fairness & Explainability: setup --- #\n",
    "\n",
    "**Цель.** Оценить справедливость и качество финальной модели на тесте, выбрать рабочий порог `t*` с учетом fairness-ограничений, проверить калибровку по группам и объяснить вклад признаков.\n",
    "\n",
    "**Входы (из `01_data_loading_and_eda.ipynb`/`02_modeling.ipynb`):**\n",
    "1. `X_test_enc`, `y_true_test`, `feature_names` - подготовка из `02_modeling.ipynb`.\n",
    "2. `y_proba_best` - прогнозы лучшей модели на тесте.\n",
    "3. `X_test_sens` - чувствительные признаки (`sex`, `race`, `age_group`).\n",
    "\n",
    "**Выходы (в `data/reports/figures_03/`, `data/artifacts`):**\n",
    "1. Пороговый скан и Pareto: `accuracy_f1_vs_threshold.png`, `dp_vs.threshold.png`, `Pareto_f1_vs_dp.png`.\n",
    "2. Метрики по группам при `t=0.5` и `t*`: таблицы CSV и бар-чарты.\n",
    "3. Калибровка по группам: `calibration_*.png` и сводная ЕСЕ.\n",
    "4. Explainability: топ-фичи (SHAP/permutation), dependence-plots.\n",
    "5. Служебные артефакты: выбранный `t*`, параметры пост-обработки (если применяли `ThresholdOptimizer`).\n",
    "\n",
    "**Содержимое ноутбука:**\n",
    "1. Sanity-checks: размеры, NaN, распределение `y_proba`.\n",
    "2. Базовые метрики при `t=0.5`.\n",
    "3. Fairness по группам при `t=0.5`.\n",
    "4. Пороговый скан -> выбор `t*` (компромисс качество <-> справедливость).\n",
    "5. Пост-обработка (`ThresholdOptimizer`: `demographic_parity` / `equalized_odds`).\n",
    "6. Калибровка вероятностей по группам (reliability curves, ECE).\n",
    "7. Explainability: глобально и локально.\n",
    "8. Риски, ограничения, рекомендации. Экспорт артефактов.\n",
    "\n",
    "**Требования к окружению и путям:**\n",
    "1. `ROOT`, `ART_DIR`, `REPORTS_DIR`, `FIG_DIR_03 = REPORTS_DIR/'    FIGURES_03'` должны существовать.\n",
    "2. Все пути и объекты загружаются через единый загрузчик артефактов из `02_modeling.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Project paths bootstrаp --- #\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# попытка использовать штатный модуль путей проекта #\n",
    "try:\n",
    "    from paths import (\n",
    "        ART_DIR,\n",
    "        DATA_DIR,\n",
    "        INT_DIR,\n",
    "        MODELS_DIR,\n",
    "        NB_DIR,\n",
    "        PROC_DIR,\n",
    "        RAW_DIR,\n",
    "        REPORTS_DIR,\n",
    "        ROOT,\n",
    "    )\n",
    "\n",
    "    print(f\"[paths] ROOT = {ROOT}\")\n",
    "except Exception as e:\n",
    "    # fallback: минимально достаточные пути без побочных эффектов\n",
    "    ROOT = Path.cwd()\n",
    "    DATA_DIR = ROOT / \"data\"\n",
    "    RAW_DIR = ROOT / \"raw\"\n",
    "    INT_DIR = ROOT / \"interim\"\n",
    "    PROC_DIR = ROOT / \"processed\"\n",
    "    ART_DIR = ROOT / \"artifacts\"\n",
    "    REPORTS_DIR = ROOT / \"reports\"\n",
    "    MODELS_DIR = ROOT / \"models\"\n",
    "    NB_DIR = ROOT / \"notebooks\"\n",
    "    print(f\"[paths:fallback] ROOT = {ROOT} | reason: {e!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fairness plotting utils & output dirs --- #\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# использование paths.py; при сбое - fallback #\n",
    "try:\n",
    "    _ = REPORTS_DIR\n",
    "except NameError:\n",
    "    try:\n",
    "        from paths import REPORTS_DIR as _REPORTS_DIR\n",
    "    except Exception:\n",
    "        _REPORTS_DIR = ROOT / \"data\" / \"reports\"\n",
    "    REPORTS_DIR = globals().get(\"REPORTS_DIR\", _REPORTS_DIR)\n",
    "\n",
    "FIG_DIR_03 = REPORTS_DIR / \"figures_03\"\n",
    "FIG_DIR_03.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def _ensure_png(name: str) -> str:\n",
    "    return name if name.lower().endswith(\".png\") else f\"{name}.png\"\n",
    "\n",
    "\n",
    "def save_fig(name: str, fig=None, dpi: int = 200, close: bool = True):\n",
    "    \"\"\"\n",
    "    Сохранение фигуры в `reports/figures_03/`\n",
    "    name: имя файла, можно без .png\n",
    "    fig: matplotlib.figure.Figure или None -> взять текущую.\n",
    "    \"\"\"\n",
    "    if not isinstance(name, str) or not name:\n",
    "        raise TypeError('save_fig: \"name\" должен быть непустой строкой.')\n",
    "\n",
    "    # импорт pyplot только при необходимости #\n",
    "    if fig is None:\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        fig = plt.gcf()\n",
    "    else:\n",
    "        # простая проверка интерфейса\n",
    "        if not hasattr(fig, \"savefig\"):\n",
    "            raise TypeError('save_fig: \"fig\" должен иметь метод savefig.')\n",
    "\n",
    "    fname = _ensure_png(name)\n",
    "    path = FIG_DIR_03 / fname\n",
    "\n",
    "    # сохранение #\n",
    "    fig.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n",
    "\n",
    "    # аккуратное закрытие только если явно просили #\n",
    "    if close:\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "\n",
    "            plt.close(fig)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    print(f\"[saved] {path}\")\n",
    "    return Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fairness & Explainability: setup --- #\n",
    "\n",
    "import warnings\n",
    "\n",
    "# централизованное подавление предупреждений #\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "FAIRLEARN_OK = False\n",
    "THRESH_OPT_OK = False\n",
    "SHAP_OK = False\n",
    "\n",
    "# fairlearn и компоненты #\n",
    "try:\n",
    "    from fairlearn.metrics import (\n",
    "        demographic_parity_difference,\n",
    "        equalized_odds_difference,\n",
    "    )\n",
    "    from fairlearn.postprocessing import ThresholdOptimizer\n",
    "\n",
    "    FAIRLEARN_OK = True\n",
    "    THRESH_OPT_OK = True\n",
    "    print(\"[ok] fairlearn импортирован.\")\n",
    "except Exception as e:\n",
    "    print(f\"[warn] fairlearn недоступен: {e!r}\")\n",
    "\n",
    "# SHAP (глобальная интерпретируемость) #\n",
    "try:\n",
    "    import shap\n",
    "\n",
    "    SHAP_OK = True\n",
    "    print(\"[ok] shap импортирован.\")\n",
    "except Exception as e:\n",
    "    print(f\"[warn] shap недоступен: {e!r}\")\n",
    "\n",
    "# служебный флаг-индикатор готовности Explainability/Fairness #\n",
    "EXPL_OK = FAIRLEARN_OK or SHAP_OK\n",
    "print(f\"[setup] FAIRLEARN_OK={FAIRLEARN_OK}, SHAP_OK={SHAP_OK}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Notebook preamble: silence & style --- #\n",
    "\n",
    "# autoreload только если доступен IPython #\n",
    "try:\n",
    "    ip = get_ipython()\n",
    "    if ip:\n",
    "        ip.run_line_magic(\"load_ext\", \"autoreload\")\n",
    "        ip.run_line_magic(\"autoreload\", \"2\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import logging\n",
    "\n",
    "# приглушение шумных логгеров #\n",
    "for name in (\"matplotlib\", \"numba\"):\n",
    "    try:\n",
    "        logging.getLogger(name).setLevel(logging.ERROR)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# единый стиль графиков #\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.grid\": True,\n",
    "        \"grid.alpha\": 0.25,\n",
    "        \"figure.figsize\": (6.5, 4.0),\n",
    "        \"axes.titlesize\": 13,\n",
    "        \"axes.labelsize\": 11,\n",
    "        \"xtick.labelsize\": 10,\n",
    "        \"ytick.labelsize\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"[preamble] style set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paths & unified artifact loader --- #\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# базовые пути из проекта; при ошибке — fallback к структуре data/* #\n",
    "try:\n",
    "    from paths import ART_DIR as _ART_DIR\n",
    "    from paths import MODELS_DIR as _MODELS_DIR\n",
    "    from paths import REPORTS_DIR as _REPORTS_DIR\n",
    "    from paths import ROOT\n",
    "except Exception:\n",
    "    ROOT = Path.cwd()\n",
    "    while (\n",
    "        not any((ROOT / m).exists() for m in (\".git\", \"pyproject.toml\", \"README.md\"))\n",
    "        and ROOT.parent != ROOT\n",
    "    ):\n",
    "        ROOT = ROOT.parent\n",
    "    _ART_DIR = ROOT / \"data\" / \"artifacts\"\n",
    "    _MODELS_DIR = ROOT / \"data\" / \"models\"\n",
    "    _REPORTS_DIR = ROOT / \"data\" / \"reports\"\n",
    "\n",
    "# NB_DIR от реального ROOT, без несуществующего _ROOT #\n",
    "NB_DIR = (ROOT / \"notebooks\") if \"ROOT\" in locals() else (Path.cwd() / \"notebooks\")\n",
    "\n",
    "ART_DIR = _ART_DIR\n",
    "MODELS_DIR = _MODELS_DIR\n",
    "REPORTS_DIR = _REPORTS_DIR\n",
    "\n",
    "CANDIDATE_ART_DIRS = [ART_DIR, NB_DIR / \"data\" / \"artifacts\"]\n",
    "CANDIDATE_MODEL_DIRS = [MODELS_DIR, ART_DIR, NB_DIR / \"data\" / \"models\"]\n",
    "FIG_DIR_02 = REPORTS_DIR / \"figures_02\"\n",
    "FIG_DIR_03 = REPORTS_DIR / \"figures_03\"\n",
    "\n",
    "\n",
    "def _pick_file(names: list[str], dirs: list[Path]) -> Path | None:\n",
    "    for d in dirs:\n",
    "        for n in names:\n",
    "            p = Path(d) / n\n",
    "            if p.exists():\n",
    "                return p\n",
    "    return None\n",
    "\n",
    "\n",
    "# loaders: core #\n",
    "\n",
    "\n",
    "def load_feature_names():\n",
    "    p = _pick_file(\n",
    "        [\"feature_names.npy\", \"feature_names.json\", \"feature_names.txt\", \"feature_names.csv\"],\n",
    "        CANDIDATE_ART_DIRS,\n",
    "    )\n",
    "    if p is None:\n",
    "        return None, None\n",
    "    if p.suffix == \".npy\":\n",
    "        return np.load(p, allow_pickle=True).tolist(), p\n",
    "    if p.suffix == \".json\":\n",
    "        return json.loads(p.read_text(encoding=\"utf-8\")), p\n",
    "    if p.suffix == \".txt\":\n",
    "        return [\n",
    "            line.strip() for line in p.read_text(encoding=\"utf-8\").splitlines() if line.strip()\n",
    "        ], p\n",
    "    if p.suffix == \".csv\":\n",
    "        return pd.read_csv(p, header=None)[0].tolist(), p\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def load_X_test_enc():\n",
    "    for nm in [\"X_test_enc.npy\", \"X_test_enc.csv\", \"X_test.npy\"]:\n",
    "        p = _pick_file([nm], CANDIDATE_ART_DIRS)\n",
    "        if p:\n",
    "            if p.suffix == \".npy\":\n",
    "                return np.load(p, allow_pickle=False), p\n",
    "            if p.suffix == \".csv\":\n",
    "                return pd.read_csv(p).to_numpy(), p\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def load_X_test_sens():\n",
    "    p = _pick_file(\n",
    "        [\"X_test_sensitive.csv\", \"X_test_sens.csv\", \"X_test_sensitive.parquet\"], CANDIDATE_ART_DIRS\n",
    "    )\n",
    "    if p is None:\n",
    "        return None, None\n",
    "    if p.suffix == \".parquet\":\n",
    "        return pd.read_parquet(p), p\n",
    "    if p.suffix == \".csv\":\n",
    "        return pd.read_csv(p), p\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def load_y_true_pred_proba():\n",
    "    y_true_p = _pick_file([\"y_true_test.npy\", \"y_true.npy\", \"y_test.npy\"], CANDIDATE_ART_DIRS)\n",
    "    y_pred_p = _pick_file([\"y_pred_best.npy\", \"y_pred.npy\"], CANDIDATE_ART_DIRS)\n",
    "    y_proba_p = _pick_file([\"y_proba_best.npy\", \"y_proba.npy\"], CANDIDATE_ART_DIRS)\n",
    "\n",
    "    def _load(p):\n",
    "        if p is None:\n",
    "            return None\n",
    "        if p.suffix == \".npy\":\n",
    "            return np.load(p, allow_pickle=False)\n",
    "        if p.suffix == \".csv\":\n",
    "            return pd.read_csv(p, header=None).iloc[:, 0].to_numpy()\n",
    "        return None\n",
    "\n",
    "    return (\n",
    "        _load(y_true_p),\n",
    "        y_true_p,\n",
    "        _load(y_pred_p),\n",
    "        y_pred_p,\n",
    "        _load(y_proba_p),\n",
    "        y_proba_p,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_best_model():\n",
    "    cand = _pick_file(\n",
    "        [\n",
    "            \"model_best.joblib\",\n",
    "            \"LGBM_best.joblib\",\n",
    "            \"lgb_best.joblib\",\n",
    "            \"XGBoost_ES_best.joblib\",\n",
    "            \"XGBoost_ES.joblib\",\n",
    "        ],\n",
    "        CANDIDATE_MODEL_DIRS,\n",
    "    )\n",
    "    if cand is None:\n",
    "        return None, None\n",
    "    try:\n",
    "        return joblib.load(cand), cand\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] cannot load {cand}: {type(e).__name__}: {e}\")\n",
    "        return None, cand\n",
    "\n",
    "\n",
    "# loaders: extras we will use in 03 #\n",
    "\n",
    "\n",
    "def load_results_df():\n",
    "    p = _pick_file([\"results_df.csv\"], CANDIDATE_ART_DIRS)\n",
    "    return (pd.read_csv(p), p) if p and p.exists() else (None, None)\n",
    "\n",
    "\n",
    "def load_results_summary():\n",
    "    p = _pick_file([\"results_summary.csv\"], CANDIDATE_MODEL_DIRS)\n",
    "    return (pd.read_csv(p), p) if p and p.exists() else (None, None)\n",
    "\n",
    "\n",
    "def load_export_meta():\n",
    "    p = _pick_file([\"export_meta.json\"], CANDIDATE_ART_DIRS)\n",
    "    return (json.loads(p.read_text(encoding=\"utf-8\")), p) if p and p.exists() else (None, None)\n",
    "\n",
    "\n",
    "def load_test_groups():\n",
    "    p = _pick_file([\"test_groups.csv\"], CANDIDATE_ART_DIRS)\n",
    "    return (pd.read_csv(p), p) if p and p.exists() else (None, None)\n",
    "\n",
    "\n",
    "def load_y_test_optional():\n",
    "    p = _pick_file([\"y_test.npy\"], CANDIDATE_ART_DIRS)\n",
    "    return (np.load(p, allow_pickle=False), p) if p and p.exists() else (None, None)\n",
    "\n",
    "\n",
    "def load_y_pred_050_optional():\n",
    "    p = _pick_file([\"y_pred_050.npy\"], CANDIDATE_ART_DIRS)\n",
    "    return (np.load(p, allow_pickle=False), p) if p and p.exists() else (None, None)\n",
    "\n",
    "\n",
    "def load_y_score_optional():\n",
    "    p = _pick_file([\"y_score.npy\"], CANDIDATE_ART_DIRS)\n",
    "    return (np.load(p, allow_pickle=False), p) if p and p.exists() else (None, None)\n",
    "\n",
    "\n",
    "def list_figures02():\n",
    "    if not FIG_DIR_02.exists():\n",
    "        return []\n",
    "    return sorted([p for p in FIG_DIR_02.glob(\"*.png\")])\n",
    "\n",
    "\n",
    "# unified summary #\n",
    "\n",
    "\n",
    "def load_artifacts_summary():\n",
    "    fn, p_fn = load_feature_names()\n",
    "    Xte, p_xe = load_X_test_enc()\n",
    "    Xsens, p_xs = load_X_test_sens()\n",
    "    y_true, p_yt, y_pred, p_yp, y_proba, p_ypr = (*load_y_true_pred_proba(),)\n",
    "    y_test_opt, p_ytest = load_y_test_optional()\n",
    "    y_pred_050_opt, p_y050 = load_y_pred_050_optional()\n",
    "    y_score_opt, p_ys = load_y_score_optional()\n",
    "    results_df, p_resdf = load_results_df()\n",
    "    results_sum, p_ressum = load_results_summary()\n",
    "    meta, p_meta = load_export_meta()\n",
    "    groups, p_groups = load_test_groups()\n",
    "    mdl, p_m = load_best_model()\n",
    "    figs02 = list_figures02()\n",
    "    return {\n",
    "        \"feature_names\": (fn, p_fn),\n",
    "        \"X_test_enc\": (Xte, p_xe),\n",
    "        \"sensitive\": (Xsens, p_xs),\n",
    "        \"y_true\": (y_true, p_yt),\n",
    "        \"y_pred\": (y_pred, p_yp),\n",
    "        \"y_proba\": (y_proba, p_ypr),\n",
    "        \"y_test_opt\": (y_test_opt, p_ytest),\n",
    "        \"y_pred_050_opt\": (y_pred_050_opt, p_y050),\n",
    "        \"y_score_opt\": (y_score_opt, p_ys),\n",
    "        \"results_df\": (results_df, p_resdf),\n",
    "        \"results_summary\": (results_sum, p_ressum),\n",
    "        \"export_meta\": (meta, p_meta),\n",
    "        \"test_groups\": (groups, p_groups),\n",
    "        \"model\": (mdl, p_m),\n",
    "        \"figures02\": (figs02, FIG_DIR_02 if figs02 else None),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Единый вызов после ячейки инициализации --- #\n",
    "\n",
    "A = load_artifacts_summary()\n",
    "\n",
    "model, model_path = A[\"model\"]\n",
    "feature_names, feature_names_path = A[\"feature_names\"]\n",
    "X_test_enc, X_test_enc_path = A[\"X_test_enc\"]\n",
    "X_test_sensitive, sens_path = A[\"sensitive\"]\n",
    "results_df, results_path = A[\"results_df\"]\n",
    "test_groups, groups_path = A[\"test_groups\"]\n",
    "y_true, y_true_path = A[\"y_true\"]\n",
    "y_proba, y_proba_path = A[\"y_proba\"]\n",
    "y_pred, y_pred_path = A[\"y_pred\"]\n",
    "\n",
    "print(\"[ok] model:\", model_path.name)\n",
    "for name, p in [\n",
    "    (\"feature_names\", feature_names_path),\n",
    "    (\"X_test_enc\", X_test_enc_path),\n",
    "    (\"sensitive\", sens_path),\n",
    "    (\"results_df\", results_path),\n",
    "    (\"test_groups\", groups_path),\n",
    "    (\"y_true\", y_true_path),\n",
    "    (\"y_proba\", y_proba_path),\n",
    "    (\"y_pred\", y_pred_path),\n",
    "]:\n",
    "    print(f\"[{'ok' if p else 'miss'}] {name}:\", (p.name if p else None))\n",
    "\n",
    "# алиасы под старые имена для совместимости #\n",
    "X_test_sens = X_test_sensitive\n",
    "y_true_test = y_true\n",
    "y_proba_best = y_proba\n",
    "y_pred_best = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- sanity-report из unified loader --- #\n",
    "\n",
    "assert \"A\" in globals()\n",
    "\n",
    "for name in [\n",
    "    \"model\",\n",
    "    \"feature_names\",\n",
    "    \"X_test_enc\",\n",
    "    \"sensitive\",\n",
    "    \"results_df\",\n",
    "    \"results_summary\",\n",
    "    \"test_groups\",\n",
    "    \"y_true\",\n",
    "    \"y_proba\",\n",
    "    \"y_test_opt\",\n",
    "    \"y_pred_050_opt\",\n",
    "    \"y_score_opt\",\n",
    "    \"export_meta\",\n",
    "    \"figures02\",\n",
    "]:\n",
    "    val, p = A[name]\n",
    "    shape = getattr(val, \"shape\", None)\n",
    "    if isinstance(val, list | tuple) and not shape:\n",
    "        shape = f\"len={len(val)}\"\n",
    "    print(f\"[{name:>14}] path={getattr(p, 'name', None)} shape={shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Provenance из export_meta.json --- #\n",
    "\n",
    "meta, p_meta = A[\"export_meta\"]\n",
    "if meta:\n",
    "    print(f\"[meta] best_model={meta.get('best_model')} | ts={meta.get('timestamp')}\")\n",
    "    arts = meta.get(\"artifacts\") or []\n",
    "    print(f\"[meta] listed artifacts: {len(arts)}\")\n",
    "else:\n",
    "    print(\"[meta] export_meta.json not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Leaderboard (results_summary.csv) --- #\n",
    "\n",
    "res_sum, p_sum = A[\"results_summary\"]\n",
    "\n",
    "if res_sum is not None:\n",
    "    df = res_sum.copy()\n",
    "    # упорядочивание по test_f1, затем roc_auc #\n",
    "    cols = [\n",
    "        c\n",
    "        for c in [\n",
    "            \"model\",\n",
    "            \"test_f1\",\n",
    "            \"test_roc_auc\",\n",
    "            \"test_precision\",\n",
    "            \"test_recall\",\n",
    "            \"test_accuracy\",\n",
    "        ]\n",
    "        if c in df.columns\n",
    "    ]\n",
    "    df = df.sort_values(\n",
    "        by=[c for c in [\"test_f1\", \"test_roc_auc\"] if c in df.columns], ascending=False\n",
    "    )\n",
    "    display(df[cols].head(10))\n",
    "else:\n",
    "    print(\"[skip] results_summary.csv absent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Consistency check: y_true vs y_test --- #\n",
    "\n",
    "y_true, _ = A[\"y_true\"]\n",
    "y_test_opt, p_ytest = A[\"y_test_opt\"]\n",
    "if y_true is not None and y_test_opt is not None:\n",
    "    same = np.array_equal(y_true, y_test_opt)\n",
    "    print(f\"[check] y_true vs y_test: {'OK' if same else 'MISMATCH'}\")\n",
    "    if not same:\n",
    "        raise RuntimeError(\"y_true_test.npy и y_test.npy различаются.\")\n",
    "else:\n",
    "    print(\"[check] y_test optional not found -> skip.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# --- sanity-check: размеры, NaN, распределение y_proba --- #\n",
    "\n",
    "**Цель.** Проверить согласованность входных данных и корректность вероятностных прогнозов, прежде чем проводить анализ справедливости и объяснимости.\n",
    "\n",
    "**Этапы проверки:**\n",
    "1. Размерности. Убедиться, что длины `X_test_enc`, `X_test_sens`, `y_true_test`, `y_proba_best` совпадают. Несовпадение сигнализирует о нарушении консистентности между признаками, метками и предсказаниями модели.\n",
    "2. Пропуски. Проверить наличие `NaN` в `y_proba_best` и чувствительных признаках. Их присутствие может исказить распределения и метрики fairness.\n",
    "3. Распределение вероятностей:\n",
    "    - вывести базовую статистику (`min`, `max`, `mean`, `std`);\n",
    "    - построить гистограмму распределения `y_proba_best`;\n",
    "    - визуально оценить баланс классов: есть ли смещение вероятностей в сторону 0 или 1.\n",
    "4. Срезы по группам. Если в `X_test_sens` присутствуют `sex`, `race`, `age_group`, то дополнительно сравнить средние значения `y_proba_best` по группам - это ранний индикатор возможного смещения модели.\n",
    "\n",
    "**Интерпретация:**\n",
    "1. Равные размеры и отсутствие пропусков подтверждают корректность подготовки артефактов.\n",
    "2. Сбалансированное распределение `y_proba_best` указывает на отсутствие сильной переуверенности модели.\n",
    "3. Различия между группами на данном этапе - лишь диагностический сигнал, не статистически значимая мера fairness.\n",
    "\n",
    "**Ожидаемый результат.** Построена гистограмма распределения `y_proba_best`, проверены базовые размеры и отсутствуют `NaN`. На выходе получаем подтверждение, что входные данные пригодны для расчета метрик справедливости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- sanity-check: размеры, NaN, распределение y_proba --- #\n",
    "\n",
    "# проверка присутствия артефактов из A #\n",
    "assert all(k in globals() for k in [\"y_true_test\", \"y_pred_best\", \"y_proba_best\", \"X_test_sens\"]), (\n",
    "    \"Нет алиасов от unified loader.\"\n",
    ")\n",
    "\n",
    "# согласованность размеров #\n",
    "n = len(y_true_test)\n",
    "assert len(y_pred_best) == n and len(y_proba_best) == n, \"Длины y_* не совпадают\"\n",
    "assert len(X_test_sens) == n, \"Длина X_test_sens не совпадает с y\"\n",
    "\n",
    "# NaN и допустимый диапазон #\n",
    "assert np.isfinite(y_proba_best).all(), \"Есть NaN/Inf в y_proba_best\"\n",
    "assert (y_proba_best >= 0).all() and (y_proba_best <= 1).all(), \"y_proba_best вне [0, 1]\"\n",
    "\n",
    "# гистограмма вероятностей #\n",
    "plt.figure()\n",
    "plt.hist(y_proba_best, bins=30)\n",
    "plt.xlabel(\"y_proba_best\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Распределение предсказанных вероятностей\")\n",
    "plt.tight_layout()\n",
    "save_fig(\"hist_y_proba_best.png\")\n",
    "plt.show()\n",
    "\n",
    "# базовый pos_rate по группам (t = 0.5) #\n",
    "t = 0.5\n",
    "y_pred_05 = (y_proba_best >= t).astype(\"int8\")\n",
    "\n",
    "pred_ser = pd.Series(y_pred_05, index=X_test_sens.index, name=\"y_pred_05\")\n",
    "\n",
    "for gcol in [c for c in [\"sex\", \"race\", \"age_group\"] if c in X_test_sens.columns]:\n",
    "    grp = X_test_sens[gcol].fillna(\"NA\")\n",
    "    rates = pred_ser.groupby(grp).mean().sort_values(ascending=False)\n",
    "    print(f\"[{gcol}] selection rate @ t = 0.5:\")\n",
    "    print(rates, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# --- Определение чувствительных признаков и групп --- #\n",
    "\n",
    "**Цель.** Задать список чувствительных признаков (sensitive features), по которым будет оцениваться справедливость модели, и обеспечить корректную подготовку групп для последующих метрик.\n",
    "\n",
    "**Выбор признаков.** В соответствии с постановкой задачи *Census Income Classifier*, к чувствительным признакам относятся:\n",
    "1. `sex` - бинарный (Male/Female).\n",
    "2. `race` - категориальный (White/Black/Asian-Pac-Islander/Amer-Indian-Eskimo/Other).\n",
    "3. `age_group` - дискретизированный возраст (например, 17-29, 30-44, 45-59, 60+), если присутствует в данных.\n",
    "\n",
    "**Обработка данных:**\n",
    "1. Проверяется наличие указанных признаков в `X_test_sens`.\n",
    "2. Пропуски заменяются категорией `'NA'` для сохранения полноты групп.\n",
    "3. Категориальные признаки приводятся к `category` dtype с фиксированным порядком категорий, чтобы избежать некорректного сравнения по алфавиту.\n",
    "4. При необходимости малочисленные категории можно агрегировать в `'Other'`.\n",
    "\n",
    "**Интерпретация.** Корректное определение чувствительных признаков гарантирует, что fairness-метрики (Demographic Parity, Equalized Odds и др.) будут рассчитаны для сопоставимых групп, а результаты останутся интерпретируемыми.\n",
    "\n",
    "**Ожидаемый результат.** Сформирован DataFrame `X_test_sens` с обработанными чувствительными признаками, готовый к использованию в блоках fairness-анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Чувствительные признаки и группы --- #\n",
    "\n",
    "# гарантия наличия X_test_sens из unified loader #\n",
    "assert \"X_test_sens\" in globals(), \"X_test_sens должен быть из unified loader.\"\n",
    "\n",
    "CAND_SENSITIVE = [\"sex\", \"race\", \"age_group\"]\n",
    "SENSITIVE = [c for c in CAND_SENSITIVE if c in X_test_sens.columns]\n",
    "print(\"Используем SENSITIVE:\", SENSITIVE)\n",
    "\n",
    "# осмысленный порядок для age_group #\n",
    "if \"age_group\" in SENSITIVE:\n",
    "    desired_order = [\"18-25\", \"26-45\", \"46-65\", \"65+\"]\n",
    "    try:\n",
    "        X_test_sens[\"age_group\"] = pd.Categorical(\n",
    "            X_test_sens[\"age_group\"], categories=desired_order, ordered=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"Не удалось задать порядок для age_group:\", e)\n",
    "\n",
    "# собираем уникальные значения по каждой чувствительной переменной #\n",
    "GROUP_VALUES = {}\n",
    "for col in SENSITIVE:\n",
    "    vals = X_test_sens[col].dropna().unique().tolist()\n",
    "    if (col == \"age_group\") and hasattr(X_test_sens[col], \"cat\"):\n",
    "        vals = [v for v in X_test_sens[col].cat.categories if v in set(X_test_sens[col].dropna())]\n",
    "        GROUP_VALUES[col] = list(vals)\n",
    "\n",
    "# отчет по наличию групп и их размерам #\n",
    "for col in SENSITIVE:\n",
    "    print(f\"\\n[{col}] группы и размерности:\")\n",
    "    df_sizes = (\n",
    "        X_test_sens[col]\n",
    "        .value_counts(dropna=False)\n",
    "        .rename_axis(\"group\")\n",
    "        .reset_index(name=\"n\")\n",
    "        .assign(share=lambda d: d[\"n\"] / len(X_test_sens))\n",
    "    )\n",
    "    display(df_sizes)\n",
    "\n",
    "print(\"\\nGROUP_VALUES =\", GROUP_VALUES)\n",
    "\n",
    "# главная чувсвительная переменная #\n",
    "PRIMARY_SENS = SENSITIVE[0] if SENSITIVE else None\n",
    "print(\"PRIMARY_SENS:\", PRIMARY_SENS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# --- Базовая линия: метрики на общем пороге (0.5) --- #\n",
    "\n",
    "**Цель.** Рассчитать ключевые метрики качества модели при фиксированном пороге `t=0.5`, который используется как базовая линия для дальнейшего анализа компромисса *качество <-> справедливость*.\n",
    "\n",
    "**Метрики оценки:**\n",
    "1. Accuracy - доля верно классифицированных наблюдений.\n",
    "2. Precision - точность положительных предсказаний.\n",
    "3. Recall - полнота выявления положительного класса.\n",
    "4. F1-score - гармоническое среднее между Precision и Recall.\n",
    "5. ROC-AUC - способность модели разделять классы независимо от порога.\n",
    "\n",
    "**Интерпретация.** Порог `0.5` отражает \"нейтральную\" точку отсечения, не скорректированную под дисбаланс классов или требования fairness. Полученные значения служат:\n",
    "1. Отправной точкой для поиска оптимального порога `t*`.\n",
    "2. Контрольной базой при сравнении с пост-обработкой (`ThresholdOptimizer`).\n",
    "3. Ориентиром для оценки влияния fairness-ограничений на качество.\n",
    "\n",
    "**Ожидаемый результат.** Выведена таблица или словарь со значениями Accuracy, Precision, Recall, F1, ROC-AUC для `t=0.5`. Эти показатели будут использованы далее при построении пороговой кривой и Pareto-графика."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовые метрики на t = 0.5 #\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# бинарные предсказания при пороге 0.5 #\n",
    "y_pred_05 = (y_proba_best >= 0.5).astype(int)\n",
    "\n",
    "base_metrics = {\n",
    "    \"accuracy\": accuracy_score(y_true_test, y_pred_05),\n",
    "    \"f1\": f1_score(y_true_test, y_pred_05),\n",
    "    \"precision\": precision_score(y_true_test, y_pred_05, zero_division=0),\n",
    "    \"roc_auc\": roc_auc_score(y_true_test, y_proba_best),\n",
    "    \"recall\": recall_score(y_true_test, y_pred_05, zero_division=0),\n",
    "}\n",
    "\n",
    "print(\"Базовые метрики (t = 0.5):\")\n",
    "display(pd.DataFrame([base_metrics]).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# --- Fairness по группам при t = 0.5 --- #\n",
    "\n",
    "**Цель.** Оценить, насколько модель демонстрирует различия в качестве предсказаний между чувствительными группами при базовом пороге `t=0.5`.\n",
    "\n",
    "**Используемые показатели:**\n",
    "1. Selection Rate (SR) - доля объектов, классифицированных как положительные, в каждой группе.\n",
    "2. True Positive Rate (TPR) и False Positive Rate (FPR) - чувствительность и ложноположительная частота по группам.\n",
    "3. Precision, Recall, F1 - классические метрики производительности, рассчитанные отдельно для каждой категории чувствительного признака.\n",
    "4. Demographic Parity Difference - различие в чувствительности между группами.\n",
    "\n",
    "**Интерпретация:**\n",
    "1. Различия в SR и TPR/FPR отражают потенциальное смещение модели в отношении разных подгрупп населения.\n",
    "2. При значимых отклонениях (например, высокий SR у одной и низкий у другой) fairness-ограничения могут оказаться необходимыми на этапе пост-обработки.\n",
    "3. Порог `0.5` здесь играет роль отправной точки, чтобы измерить масштаб возможного дисбаланса перед оптимизацией порога `t*`.\n",
    "\n",
    "**Визуализация и результаты:**\n",
    "1. Таблицы метрик по группам сохраняются в `reports/figures_03/` как CSV-файлы.\n",
    "2. Для каждой метрики формируются бар-чарты (`bar_f1_by_*.png`, `bar_precision_by_*.png`, `bar_recall_by_*.png`).\n",
    "3. Дополнительно строятся confusion-матрицы по группам для анализа типов ошибок.\n",
    "\n",
    "**Ожидаемый результат.** Выведены сводные таблицы и визуализации метрик fairness при `t=0.5`. Эти результаты служат базой для выбора оптимального порога на следующем этапе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Групповые fairness-метрики при t = 0.5 --- #\n",
    "\n",
    "from fairlearn.metrics import demographic_parity_ratio, equalized_odds_difference\n",
    "\n",
    "t = 0.5\n",
    "y_pred = (y_proba_best >= t).astype(\"int8\")\n",
    "\n",
    "# DP/EOD @ t=0.5 #\n",
    "# выбор чувствительного признака #\n",
    "sf_col = globals().get(\"PRIMARY_SENS\", None) or \"sex\"\n",
    "sf = X_test_sens[sf_col]\n",
    "\n",
    "dp_diff = demographic_parity_difference(y_true=y_true_test, y_pred=y_pred_05, sensitive_features=sf)\n",
    "dp_ratio = demographic_parity_ratio(y_true=y_true_test, y_pred=y_pred_05, sensitive_features=sf)\n",
    "eod_diff = equalized_odds_difference(y_true=y_true_test, y_pred=y_pred_05, sensitive_features=sf)\n",
    "\n",
    "print(\n",
    "    f\"[fairness@0.5] {sf_col}: \"\n",
    "    f\"DP diff={dp_diff:.4f}, \"\n",
    "    f\"DP ratio={dp_ratio:.4f}, \"\n",
    "    f\"EOD diff={eod_diff:.4f}\"\n",
    ")\n",
    "\n",
    "_agg = {\n",
    "    \"settings\": \"t=0.5\",\n",
    "    \"sf_col\": sf_col,\n",
    "    \"dp_diff\": dp_diff,\n",
    "    \"dp_ratio\": dp_ratio,\n",
    "    \"eod_diff\": eod_diff,\n",
    "}\n",
    "pd.DataFrame([_agg]).to_csv(FIG_DIR_03 / \"fairness_overview_t05.csv\", index=False)\n",
    "\n",
    "\n",
    "def _prec(y_true, y_pred):\n",
    "    return precision_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "\n",
    "def _rec(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "\n",
    "def _f1(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "\n",
    "def _acc(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- score diagnostics from y_score.npy --- #\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "y_score_opt, _ = A[\"y_score_opt\"]\n",
    "y_true, _ = A[\"y_true\"]\n",
    "if y_score_opt is not None:\n",
    "    y_score_norm = (y_score_opt - np.min(y_score_opt)) / (np.ptp(y_score_opt) + 1e-12)\n",
    "    prob_true, prob_pred = calibration_curve(y_true, y_score_norm, n_bins=10, strategy=\"quantile\")\n",
    "    df_cal = pd.DataFrame({\"preb_pred\": prob_pred, \"prob_true\": prob_true})\n",
    "    df_cal.to_csv(ART_DIR / \"calibration_from_score_quantile.csv\", index=False)\n",
    "    print(\"[ok] saved:\", ART_DIR / \"calibration_from_score_quantile.csv\")\n",
    "else:\n",
    "    print(\"[skip] y_score.npy absent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "# --- Пороговая кривая и Pareto: качество vs Demographic Parity --- #\n",
    "\n",
    "**Цель.** Найти рабочий порог классификации `t*`, обеспечивающий оптимальный баланс между качеством модели и соблюдением принципов справедливости.\n",
    "\n",
    "**Методика:**\n",
    "1. Выполняется пороговый скан: метрики качества (Accuracy, F1) и fairness-показатели (Demographic Parity/Ratio, Equalized Odds Defference) рассчитываются на сетке значений `t ∈ [0, 1]`.\n",
    "2. На основе результатов строятся кривые:\n",
    "    - `accuracy_f1_vs_threshold.png` - динамика качества при изменении порога;\n",
    "    - `dp_vs_threshold.png` - зависимость справедливости от порога;\n",
    "    - `Pareto_f1_vs_dp.png` - компромисс между F1 и Demographic Parity.\n",
    "3. Порог `t*` выбирается как точка Парето-оптимума: улучшение одной метрики без ухудшения другой становится невозможным.\n",
    "\n",
    "**Интерпретация:**\n",
    "1. При смещенной модели снижение Demographic Parity Difference обычно сопровождается потерей F1.\n",
    "2. Оптимальный порог `t*` минимизирует этот компромисс, фиксируя устойчивый баланс.\n",
    "3. В дальнейшем `t*` используется как основной порог для построения confusion-матриц, fairness-метрик и calibration-plots.\n",
    "\n",
    "**Визуализация и результаты:**\n",
    "1. Графики сохраняются в `reports/figures_03`.\n",
    "2. Таблица с метриками по порогам (Accuracy, F1, DP, EOD) сохраняется в CSV для прозрачности аудита.\n",
    "3. Отдельно сохраняется выбранный порог `t*` как артефакт (`t_star.npy`).\n",
    "\n",
    "**Ожидаемый результат.** Построены пороговые кривые и Pareto-график. Определен и сохранен рабочий порог `t*`, отражающий оптимальный баланс между качеством и справедливостью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Пороговый скан + Pareto + выбор t* + сохранение графиков --- #\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# заполнение NaN в sens-серии #\n",
    "def _sens_fill(s: pd.Series) -> pd.Series:\n",
    "    s = s.copy()\n",
    "    if isinstance(s.dtype, pd.CategoricalDtype):\n",
    "        if \"NA\" not in s.cat.categories:\n",
    "            s = s.cat.add_categories([\"NA\"])\n",
    "        return s.fillna(\"NA\")\n",
    "    else:\n",
    "        return s.fillna(\"NA\")\n",
    "\n",
    "\n",
    "# какие чувствительные признаки есть в X_test_sens #\n",
    "sens_cols = [c for c in [\"sex\", \"race\", \"age_group\"] if c in X_test_sens.columns]\n",
    "if not sens_cols:\n",
    "    raise RuntimeError(\n",
    "        \"В X_test_sens не найдено ни одного из ожидаемых чувствительных \"\n",
    "        \"признаков: sex/race/age_group.\"\n",
    "    )\n",
    "\n",
    "# ensure y_true_test / y_proba_best присутствуют #\n",
    "assert \"y_true_test\" in globals() and \"y_proba_best\" in globals(), (\n",
    "    \"Нужны y_true_test и y_proba_best из 02_modeling.\"\n",
    ")\n",
    "\n",
    "# выравнивание индексов по X_test_sens #\n",
    "y_true = pd.Series(y_true_test, index=X_test_sens.index)\n",
    "y_proba = pd.Series(y_proba_best, index=X_test_sens.index)\n",
    "\n",
    "try:\n",
    "    auc_once = roc_auc_score(y_true, y_proba)\n",
    "except Exception:\n",
    "    auc_once = np.nan\n",
    "\n",
    "# Формирование пороговой таблицы #\n",
    "ts = np.round(np.arange(0.05, 0.95, 0.01), 2)\n",
    "rows = []\n",
    "for t in ts:\n",
    "    # бинаризация вероятностей на том же индексе\n",
    "    y_pred_t = (y_proba >= t).astype(int)\n",
    "\n",
    "    # базовые метрики на выровненных сериях\n",
    "    m_f1 = f1_score(y_true, y_pred_t, zero_division=0)\n",
    "    m_pr = precision_score(y_true, y_pred_t, zero_division=0)\n",
    "    m_rc = recall_score(y_true, y_pred_t, zero_division=0)\n",
    "    m_acc = accuracy_score(y_true, y_pred_t)\n",
    "    m_auc = auc_once\n",
    "\n",
    "    # DP-разница по максимуму среди имеющихся чувствительных признаков\n",
    "    dp_diffs = []\n",
    "    for col in sens_cols:\n",
    "        s = _sens_fill(X_test_sens[col])\n",
    "        grp_name = s.name or col\n",
    "\n",
    "        # категоризация и фиксированный порядок групп\n",
    "        if grp_name in GROUP_VALUES:\n",
    "            s = pd.Series(\n",
    "                pd.Categorical(s, categories=GROUP_VALUES[grp_name], ordered=False),\n",
    "                index=y_pred_t.index,\n",
    "                name=grp_name,\n",
    "            )\n",
    "        else:\n",
    "            s = pd.Series(s, index=y_pred_t.index, name=grp_name)\n",
    "\n",
    "        # будущий дефолт pandas: observed=True\n",
    "        grp_rates = y_pred_t.groupby(s, observed=True).mean()\n",
    "\n",
    "        # восстановление полного порядка групп\n",
    "        if grp_name in GROUP_VALUES:\n",
    "            grp_rates = grp_rates.reindex(GROUP_VALUES[grp_name])\n",
    "\n",
    "        # расчет disparate impact/difference\n",
    "        dp = float(grp_rates.max() - grp_rates.min())\n",
    "        dp_diffs.append(dp)\n",
    "\n",
    "    # если все NaN — вернётся np.nan #\n",
    "    dp_diff_max = float(np.nanmax(dp_diffs)) if len(dp_diffs) else np.nan\n",
    "\n",
    "    # EOD #\n",
    "    eod_diffs = []\n",
    "    try:\n",
    "        mask_pos = y_true == 1\n",
    "        for col in sens_cols:\n",
    "            s = _sens_fill(X_test_sens[col])\n",
    "            grp_name = s.name or col\n",
    "\n",
    "            if grp_name in GROUP_VALUES:\n",
    "                s = pd.Series(\n",
    "                    pd.Categorical(s, categories=GROUP_VALUES[grp_name], ordered=False),\n",
    "                    index=y_true.index,\n",
    "                    name=grp_name,\n",
    "                )\n",
    "                groups_iter = GROUP_VALUES[grp_name]\n",
    "            else:\n",
    "                s = pd.Series(s, index=y_true.index, name=grp_name)\n",
    "                groups_iter = pd.unique(s)\n",
    "\n",
    "            tprs = []\n",
    "            for g in groups_iter:\n",
    "                m = (s == g) & mask_pos\n",
    "                if m.sum() > 0:\n",
    "                    tprs.append((y_pred_t[m] == 1).mean())\n",
    "            if len(tprs) > 1:\n",
    "                eod_diffs.append(float(np.max(tprs) - np.min(tprs)))\n",
    "        eod_diff_max = float(np.nanmax(eod_diffs)) if eod_diffs else np.nan\n",
    "    except Exception:\n",
    "        eod_diff_max = np.nan\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"t\": t,\n",
    "            \"f1\": m_f1,\n",
    "            \"precision\": m_pr,\n",
    "            \"recall\": m_rc,\n",
    "            \"accuracy\": m_acc,\n",
    "            \"auc\": m_auc,\n",
    "            \"dp_diff_max\": dp_diff_max,\n",
    "            \"eod_diff_max\": eod_diff_max,\n",
    "        }\n",
    "    )\n",
    "\n",
    "scan_df = pd.DataFrame(rows)\n",
    "\n",
    "# экспорт csv #\n",
    "ART_DIR = globals().get(\"ART_DIR\", Path(\"data\") / \"artifacts\")\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "out_csv = ART_DIR / \"fairness_threshold_scan.csv\"\n",
    "scan_df.to_csv(out_csv, index=False)\n",
    "print(f\"Saved fairness_threshold_scan.csv -> {out_csv}\")\n",
    "\n",
    "# копия в reports #\n",
    "REPORTS_DIR = globals().get(\"REPORTS_DIR\", Path(\"data\") / \"reports\")\n",
    "FIG_DIR_03 = REPORTS_DIR / \"figures_03\"\n",
    "FIG_DIR_03.mkdir(parents=True, exist_ok=True)\n",
    "out_csv_rep = FIG_DIR_03 / \"fairness_threshold_scan.csv\"\n",
    "scan_df.to_csv(out_csv_rep, index=False)\n",
    "print(f\"Copied to reports -> {out_csv_rep}\")\n",
    "\n",
    "# Pareto: F1 vs DP #\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ax.scatter(scan_df[\"dp_diff_max\"], scan_df[\"f1\"], s=14, alpha=0.85)\n",
    "ax.set_xlabel(\"Demographic Parity (max group diff)\")\n",
    "ax.set_ylabel(\"F1\")\n",
    "ax.set_title(\"Pareto: F1 vs DP\")\n",
    "\n",
    "# выделение лучшей по F1 точки #\n",
    "best_idx = int(scan_df[\"f1\"].idxmax())\n",
    "ax.scatter(\n",
    "    [scan_df.loc[best_idx, \"dp_diff_max\"]], [scan_df.loc[best_idx, \"f1\"]], s=60, edgecolors=\"k\"\n",
    ")\n",
    "for k in [\"dp_diff_max\", \"f1\", \"t\"]:\n",
    "    ax.annotate(\n",
    "        f\"{k}={scan_df.loc[best_idx, k]:.3f}\",\n",
    "        (scan_df.loc[best_idx, \"dp_diff_max\"], scan_df.loc[best_idx, \"f1\"]),\n",
    "        xytext=(10, 10),\n",
    "        textcoords=\"offset points\",\n",
    "        fontsize=8,\n",
    "    )\n",
    "save_fig(\"Pareto_f1_vs_dp.png\", fig)\n",
    "\n",
    "# метрики vs порог #\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ax.plot(scan_df[\"t\"], scan_df[\"accuracy\"], label=\"accuracy\")\n",
    "ax.plot(scan_df[\"t\"], scan_df[\"f1\"], label=\"f1\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"threshold t\")\n",
    "ax.set_ylabel(\"score\")\n",
    "ax.set_title(\"Accuracy & F1 vs threshold\")\n",
    "ax.legend()\n",
    "save_fig(\"accuracy_f1_vs_threshold.png\", fig)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ax.plot(scan_df[\"t\"], scan_df[\"dp_diff_max\"])\n",
    "ax.set_xlabel(\"threshold t\")\n",
    "ax.set_ylabel(\"DP max diff\")\n",
    "ax.set_title(\"DP (max group diff) vs threshold\")\n",
    "save_fig(\"dp_vs_threshold.png\", fig)\n",
    "\n",
    "# EOD #\n",
    "if scan_df[\"eod_diff_max\"].notna().any():\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    ax.plot(scan_df[\"t\"], scan_df[\"eod_diff_max\"])\n",
    "    ax.set_xlabel(\"threshold t\")\n",
    "    ax.set_ylabel(\"EOD max diff\")\n",
    "    ax.set_title(\"EOD (max group diff) vs threshold\")\n",
    "    save_fig(\"eod_vs_threshold.png\", fig)\n",
    "\n",
    "# Pareto-front: F1 vs DP #\n",
    "scan_df[\"dp_abs\"] = scan_df[\"dp_diff_max\"].abs()\n",
    "\n",
    "pareto_idx = []\n",
    "for i, r in scan_df.iterrows():\n",
    "    dominated = (\n",
    "        (scan_df[\"f1\"] >= r[\"f1\"])\n",
    "        & (scan_df[\"dp_abs\"] <= r[\"dp_abs\"])\n",
    "        & ((scan_df[\"f1\"] > r[\"f1\"]) | (scan_df[\"dp_abs\"] < r[\"dp_abs\"]))\n",
    "    ).any()\n",
    "    if not dominated:\n",
    "        pareto_idx.append(i)\n",
    "pareto_df = scan_df.loc[pareto_idx]\n",
    "\n",
    "# критерий выбора: минимальный |DP|, при равенстве - максимальный F1 #\n",
    "t_star = float(pareto_df.sort_values([\"dp_abs\", \"f1\"], ascending=[True, False]).iloc[0][\"t\"])\n",
    "\n",
    "# сохранить t* как артефакт #\n",
    "np.save(ART_DIR / \"t_star.npy\", np.array([t_star], dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compare metrics: t* vs t-0.5 --- #\n",
    "\n",
    "assert \"t_star\" in globals()\n",
    "y_true, _ = A[\"y_true\"]\n",
    "y_proba_best, _ = A[\"y_proba\"]\n",
    "y_pred_050_opt, _ = A[\"y_pred_050_opt\"]\n",
    "\n",
    "\n",
    "def _metrics(y_true, y_pred, y_score=None):\n",
    "    out = {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    }\n",
    "    if y_score is not None:\n",
    "        try:\n",
    "            out[\"roc_auc\"] = roc_auc_score(y_true, y_score)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return out\n",
    "\n",
    "\n",
    "# t* #\n",
    "y_pred_star = (y_proba_best >= float(t_star)).astype(int)\n",
    "m_star = _metrics(y_true, y_pred_star, y_proba_best)\n",
    "\n",
    "# t=0.5 #\n",
    "if y_pred_050_opt is not None:\n",
    "    m_050 = _metrics(y_true, y_pred_050_opt, y_proba_best)\n",
    "    comp = pd.DataFrame([m_050, m_star], index=[\"t=0.5\", \"t*\"])\n",
    "    display(comp)\n",
    "    comp.to_csv(ART_DIR / \"metrics_t050_vs_tstar.csv\", index=True)\n",
    "    print(\"[ok] saved:\", ART_DIR / \"metrics_050_vs_tstar.csv\")\n",
    "else:\n",
    "    print(\"[skip] y_pred_050.npy absent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Group metrics @ t* -> CSV --- #\n",
    "\n",
    "# входные объекты: #\n",
    "# y_true : вектор истинных меток #\n",
    "# y_proba_best : вероятности положительного класса #\n",
    "# t_star : выбранный порог #\n",
    "# X_test_sensitive : DataFrame с чувствительными признаками #\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "assert \"t_star\" in globals(), \"t_star не найден\"\n",
    "assert \"y_proba_best\" in globals(), \"y_proba_best не найден\"\n",
    "assert \"y_true\" in globals(), \"y_true не найден\"\n",
    "assert \"X_test_sensitive\" in globals(), \"X_test_sensitive не найден\"\n",
    "\n",
    "# каталоги вывода #\n",
    "ART_DIR = globals().get(\"ART_DIR\", Path(\"data\") / \"artifacts\")\n",
    "FIG_DIR_03 = globals().get(\"REPORTS_DIR\", Path(\"data\") / \"reports\") / \"figures_03\"\n",
    "\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR_03.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# предсказания на пороге t* #\n",
    "y_pred_star = (y_proba_best >= float(t_star)).astype(int)\n",
    "\n",
    "rows_metrics = []\n",
    "rows_selrate = []\n",
    "\n",
    "for col in X_test_sensitive.columns:\n",
    "    s = X_test_sensitive[col]\n",
    "    # отброс пропусков из группировки\n",
    "    for g in sorted(s.dropna().unique()):\n",
    "        m = (s == g).values\n",
    "        n = int(m.sum())\n",
    "        if n == 0:\n",
    "            continue\n",
    "        yt = y_true[m]\n",
    "        yp = y_pred_star[m]\n",
    "\n",
    "        # metrics\n",
    "        p, r, f1, _ = precision_recall_fscore_support(yt, yp, average=\"binary\", zero_division=0)\n",
    "        acc = accuracy_score(yt, yp)\n",
    "\n",
    "        rows_metrics.append(\n",
    "            {\n",
    "                \"threshold\": float(t_star),\n",
    "                \"group_col\": col,\n",
    "                \"group\": g,\n",
    "                \"n\": n,\n",
    "                \"precision\": float(p),\n",
    "                \"recall\": float(r),\n",
    "                \"f1\": float(f1),\n",
    "                \"accuracy\": float(acc),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # selection rate\n",
    "        sel = float(yp.mean()) if n > 0 else 0.0\n",
    "        rows_selrate.append(\n",
    "            {\n",
    "                \"threshold\": float(t_star),\n",
    "                \"group_col\": col,\n",
    "                \"group\": g,\n",
    "                \"n\": n,\n",
    "                \"selection_rate\": sel,\n",
    "            }\n",
    "        )\n",
    "\n",
    "df_metrics = pd.DataFrame(\n",
    "    rows_metrics,\n",
    "    columns=[\"threshold\", \"group_col\", \"group\", \"n\", \"precision\", \"recall\", \"f1\", \"accuracy\"],\n",
    ")\n",
    "df_selrate = pd.DataFrame(\n",
    "    rows_selrate, columns=[\"threshold\", \"group_col\", \"group\", \"n\", \"selection_rate\"]\n",
    ")\n",
    "\n",
    "# сохранение в отчеты и дубликат в артефакты #\n",
    "p1 = FIG_DIR_03 / \"group_metrics_t_star.csv\"\n",
    "p2 = FIG_DIR_03 / \"selection_rates_t_star.csv\"\n",
    "a1 = ART_DIR / \"group_metrics_t_star.csv\"\n",
    "a2 = ART_DIR / \"selection_rates_t_star.csv\"\n",
    "\n",
    "df_metrics.to_csv(p1, index=False)\n",
    "df_selrate.to_csv(p2, index=False)\n",
    "df_metrics.to_csv(a1, index=False)\n",
    "df_selrate.to_csv(a2, index=False)\n",
    "\n",
    "print(f\"[ok] Saved: {p1}\")\n",
    "print(f\"[ok] Saved: {p2}\")\n",
    "print(f\"[ok] Saved: {a1}\")\n",
    "print(f\"[ok] Saved: {a2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# --- Post-Processing: ThresholdOptimizer (DemographicParity / EqualizedOdds) --- #\n",
    "\n",
    "**Цель.** Применить пост-обработку для корректировки решений модели с учетом fairness-ограничений и оценить влияние этой процедуры на качество и справедливость.\n",
    "\n",
    "**Подход:**\n",
    "1. Используется метод `ThresholdOptimizer` из библиотеки fairlearn, позволяющий адаптировать порог классификации отдельно для каждой подгруппы чувствительного признака.\n",
    "2. Рассматриваются два типа ограничений:\n",
    "    - Demogrpahic Parity - выравнивание долей положительных исходов между группами;\n",
    "    - Equalize Odds - выравнивание чувствительности (TPR) и специфичности (FPR) между группами.\n",
    "\n",
    "**Методика сравнения:**\n",
    "1. Выполнить оптимизацию отдельно для каждого ограничения, используя обученную модель как черный ящик (`estimator='prefitted'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Post‑processing: ThresholdOptimizer (DP / EqOdds) --- #\n",
    "\n",
    "from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*sensitive features not unique.*\")\n",
    "\n",
    "\n",
    "# заполнение NaN в чувствительных признаках #\n",
    "def _sens_fill(s):\n",
    "    s = s.copy()\n",
    "    if isinstance(s.dtype, pd.CategoricalDtype):\n",
    "        if \"NA\" not in s.cat.categories:\n",
    "            s = s.cat.add_categories([\"NA\"])\n",
    "        return s.fillna(\"NA\")\n",
    "    else:\n",
    "        return s.fillna(\"NA\")\n",
    "\n",
    "\n",
    "# выбор доступного чувствительного признака #\n",
    "sens_cols = [c for c in [\"sex\", \"race\", \"age_group\"] if c in X_test_sens.columns]\n",
    "if not sens_cols:\n",
    "    print(\"Нет сенситивных признаков - пропуск ThresholdOptimizer\")\n",
    "else:\n",
    "    gcol = \"sex\" if \"sex\" in X_test_sens.columns else sens_cols[0]\n",
    "    sf = _sens_fill(X_test_sens[gcol])\n",
    "\n",
    "    class _ScoresEstimator:\n",
    "        \"\"\"Суррогат-классификатор, который отдает уже посчитанные вероятности.\"\"\"\n",
    "\n",
    "        def __init__(self, scores):\n",
    "            self.scores = np.asarray(scores)\n",
    "            # чтобы check_fitted не ругался при prefit=True\n",
    "            self.fitted_ = True\n",
    "\n",
    "        def get_params(self, deep=True):\n",
    "            return {\"scores\": self.scores}\n",
    "\n",
    "        def set_params(self, **params):\n",
    "            # запоминание размерности\n",
    "            return self\n",
    "\n",
    "        def fit(self, X, y):\n",
    "            self.fitted_ = True\n",
    "            # запоминание размерности\n",
    "            return self\n",
    "\n",
    "        def predict_proba(self, X):\n",
    "            # X используется только для совместимости сигнатуры;\n",
    "            # возвращаем заранее посчитанные вероятности\n",
    "            p = self.scores\n",
    "            return np.column_stack([1.0 - p, p])\n",
    "\n",
    "    # создаем surrogate-модель и \"признаки\" как индексы #\n",
    "    X_idx = np.arange(len(y_true_test)).reshape(-1, 1)\n",
    "    base_est = _ScoresEstimator(y_proba_best)\n",
    "\n",
    "    # ThresholdOptimizer под демографический паритет #\n",
    "    postproc = ThresholdOptimizer(\n",
    "        estimator=base_est,\n",
    "        constraints=\"demographic_parity\",\n",
    "        predict_method=\"predict_proba\",\n",
    "        prefit=True,\n",
    "    )\n",
    "    # fit/predict на одних и тех же X_idx #\n",
    "    postproc.fit(X=X_idx, y=y_true_test, sensitive_features=sf)\n",
    "    y_pred_dp = postproc.predict(X=X_idx, sensitive_features=sf).astype(\"int8\")\n",
    "\n",
    "    # метрики после пост-обработки #\n",
    "    def _prec(y_true, y_pred):\n",
    "        return precision_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    def _rec(y_true, y_pred):\n",
    "        return recall_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    def _f1(y_true, y_pred):\n",
    "        return f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    dp = demographic_parity_difference(y_true=y_true_test, y_pred=y_pred_dp, sensitive_features=sf)\n",
    "    eq = equalized_odds_difference(y_true=y_true_test, y_pred=y_pred_dp, sensitive_features=sf)\n",
    "\n",
    "    print(\n",
    "        f\"[ThresholdOptimizer @ {gcol}] \"\n",
    "        f\"acc={accuracy_score(y_true_test, y_pred_dp):.3f} \"\n",
    "        f\"f1={_f1(y_true_test, y_pred_dp):.3f} \"\n",
    "        f\"prec={_prec(y_true_test, y_pred_dp):.3f} \"\n",
    "        f\"rec={_rec(y_true_test, y_pred_dp):.3f} \"\n",
    "        f\"| DP diff={dp:+.3f} EqOdds diff={eq:+.3f}\"\n",
    "    )\n",
    "\n",
    "# сводная таблица метрик: baseline vs t* ThresholdOptimizer #\n",
    "rows = []\n",
    "\n",
    "\n",
    "def _metrics_row(tag, y_pred_local, sf_local):\n",
    "    return {\n",
    "        \"settings\": tag,\n",
    "        \"accuracy\": accuracy_score(y_true_test, y_pred_local),\n",
    "        \"precision\": precision_score(y_true_test, y_pred_local, zero_division=0),\n",
    "        \"recall\": recall_score(y_true_test, y_pred_local, zero_division=0),\n",
    "        \"f1\": f1_score(y_true_test, y_pred_local, zero_division=0),\n",
    "        \"dp_diff\": demographic_parity_difference(\n",
    "            y_true=y_true_test, y_pred=y_pred_local, sensitive_features=sf_local\n",
    "        ),\n",
    "        \"eod_diff\": equalized_odds_difference(\n",
    "            y_true=y_true_test, y_pred=y_pred_local, sensitive_features=sf_local\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "# baseline t=0.5 #\n",
    "y_pred_05 = (y_proba_best >= 0.5).astype(int)\n",
    "rows.append(_metrics_row(\"baseline_t0.5\", y_pred_05, sf))\n",
    "\n",
    "# baseline t* #\n",
    "if \"t_star\" in globals():\n",
    "    y_pred_star = (y_proba_best >= t_star).astype(int)\n",
    "    rows.append(_metrics_row(\"baseline_t*\", y_pred_star, sf))\n",
    "\n",
    "# post-processing DP #\n",
    "rows.append(_metrics_row(\"ThresholdOptimizer_DP\", y_pred_dp, sf))\n",
    "\n",
    "postproc_df = pd.DataFrame(rows)\n",
    "postproc_df.to_csv(FIG_DIR_03 / \"metrics_postprocessing.csv\", index=False)\n",
    "print(\"[postproc] saved:\", FIG_DIR_03 / \"metrics_postprocessing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "# --- Калибровка вероятностей по группам --- #\n",
    "\n",
    "**Цель.** Оценить согласованность вероятностных предсказаний с эмпирическими частотами положительного исхода в разных чувствительных группах.\n",
    "\n",
    "**Методика:**\n",
    "1. Для каждой доступной группы (`sex`, `race`, `age_group`) строим кривые надежности (reliability curves) по 10 равным бинам вероятностей.\n",
    "2. Считаем Expected Calibration Error (ECE) по 10 бинам.\n",
    "3. Игнорируем слишком малые подгруппы при построении графиков, задавая `min_count=50`.\n",
    "\n",
    "**Результаты:**\n",
    "1. Файлы графиков: `calibration_{group}.png` в `reports/figures_03/`.\n",
    "2. Сводная таблица ECE: `calibration_ece_by_group.png` в `reports/figures_03/`.\n",
    "\n",
    "**Интерпретация:**\n",
    "1. Линия \\(y=x\\) соответствует идеальной калибровке. Систематические отклонения указывают на пере/недоуверенность модели в конкретной группе.\n",
    "2. ECE суммирует средневзвешенную величину отклонений и служит компактным числовым индикатором калибровки по группам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Calibration plots by groups + сохранение --- #\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "\n",
    "def plot_reliability_by_groups(\n",
    "    y_true, y_proba, group_series, n_bins=10, min_count=50, title=\"\", save_name=None\n",
    "):\n",
    "    groups = group_series.value_counts().index.tolist()\n",
    "    kept = []\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    for g in groups:\n",
    "        mask = (group_series == g).to_numpy()\n",
    "        if mask.sum() < min_count:\n",
    "            continue\n",
    "        prob_true, prob_pred = calibration_curve(\n",
    "            y_true[mask], y_proba[mask], n_bins=n_bins, strategy=\"uniform\"\n",
    "        )\n",
    "        ax.plot(prob_pred, prob_true, label=f\"{g} (n={mask.sum()})\")\n",
    "        kept.append(g)\n",
    "    ax.plot([0, 1], [0, 1], \"--\", linewidth=1)\n",
    "    ax.set_xlabel(\"Predicted probability\")\n",
    "    ax.set_ylabel(\"Empirical positive rate\")\n",
    "    ax.set_title(title or f\"Calibration by {group_series.name}\")\n",
    "    if kept:\n",
    "        ax.legend()\n",
    "    if save_name:\n",
    "        save_fig(save_name, fig)\n",
    "\n",
    "\n",
    "def compute_ece(y_true, y_proba, n_bins=10):\n",
    "    # равномерная бинингация по предсказанной вероятности #\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    idx = np.digitize(y_proba, bins) - 1\n",
    "    ece = 0.0\n",
    "    N = len(y_true)\n",
    "    for b in range(n_bins):\n",
    "        mask = idx == b\n",
    "        nb = mask.sum()\n",
    "        if nb == 0:\n",
    "            continue\n",
    "        acc_b = y_true[mask].mean()\n",
    "        conf_b = y_proba[mask].mean()\n",
    "        ece += (nb / N) * abs(acc_b - conf_b)\n",
    "    return float(ece)\n",
    "\n",
    "\n",
    "# защита наличия данных #\n",
    "assert all(k in globals() for k in [\"y_true_test\", \"y_proba_best\", \"X_test_sens\"])\n",
    "\n",
    "# вызовы на все доступные чувствительные признаки #\n",
    "for col in [c for c in [\"sex\", \"race\", \"age_group\"] if c in X_test_sens.columns]:\n",
    "    plot_reliability_by_groups(\n",
    "        y_true=y_true_test,\n",
    "        y_proba=y_proba_best,\n",
    "        group_series=X_test_sens[col],\n",
    "        n_bins=10,\n",
    "        min_count=50,\n",
    "        title=f\"Calibration by {col}\",\n",
    "        save_name=f\"calibration_{col}.png\",\n",
    "    )\n",
    "\n",
    "# ECE по группам и сохранение CSV #\n",
    "ece_rows = []\n",
    "for col in [c for c in [\"sex\", \"race\", \"age_group\"] if c in X_test_sens.columns]:\n",
    "    s = X_test_sens[col]\n",
    "    # по каждой категории в признаке col\n",
    "    for g in s.dropna().unique():\n",
    "        m = (s == g).to_numpy()\n",
    "        if m.sum() == 0:\n",
    "            continue\n",
    "        ece = compute_ece(y_true=y_true_test[m], y_proba=y_proba_best[m], n_bins=10)\n",
    "        ece_rows.append({\"group_col\": col, \"group\": str(g), \"n\": int(m.sum()), \"ece10\": ece})\n",
    "\n",
    "if ece_rows:\n",
    "    pd.DataFrame(ece_rows).sort_values([\"group_col\", \"group\"]).to_csv(\n",
    "        FIG_DIR_03 / \"calibration_ece_by_group.csv\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Group metrics bar charts + сохранение --- #\n",
    "\n",
    "assert \"t_star\" in globals(), \"Ожидается выбранный порог t_star\"\n",
    "assert all(k in globals() for k in [\"y_true_test\", \"y_proba_best\", \"X_test_sens\"])\n",
    "y_pred_star = (y_proba_best >= t_star).astype(int)\n",
    "\n",
    "\n",
    "def _bar_metric_by_group(\n",
    "    y_true, y_pred, group_series, metric_fn, metric_name: str, min_count=50, save_name=\"\"\n",
    "):\n",
    "    recs = []\n",
    "    for g, idx in (\n",
    "        group_series.reset_index(drop=True)\n",
    "        .groupby(group_series.reset_index(drop=True))\n",
    "        .groups.items()\n",
    "    ):\n",
    "        idx = np.array(idx, dtype=int)\n",
    "        if len(idx) < min_count:\n",
    "            continue\n",
    "        val = metric_fn(y_true[idx], y_pred[idx])\n",
    "        recs.append({\"group\": str(g), metric_name: float(val), \"n\": int(len(idx))})\n",
    "    if not recs:\n",
    "        print(f\"[fairness] skip {metric_name}: all groups < min_count\")\n",
    "        return\n",
    "    df = pd.DataFrame(recs).sort_values(metric_name, ascending=False)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    ax.bar(df[\"group\"], df[metric_name])\n",
    "    ax.set_title(f\"{metric_name} by {group_series.name}\")\n",
    "    ax.set_ylabel(metric_name)\n",
    "    ax.set_xlabel(group_series.name)\n",
    "    for i, v in enumerate(df[metric_name].values):\n",
    "        ax.text(i, v, f\"{v:.2f}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    save_fig(save_name, fig)\n",
    "\n",
    "\n",
    "for col in [c for c in [\"sex\", \"race\", \"age_group\"] if c in X_test_sens.columns]:\n",
    "    gs = X_test_sens[col]\n",
    "    _bar_metric_by_group(\n",
    "        y_true_test,\n",
    "        y_pred_star,\n",
    "        gs,\n",
    "        precision_score,\n",
    "        \"precision\",\n",
    "        save_name=f\"bar_precision_by_{col}.png\",\n",
    "    )\n",
    "    _bar_metric_by_group(\n",
    "        y_true_test, y_pred_star, gs, recall_score, \"recall\", save_name=f\"bar_recall_by_{col}.png\"\n",
    "    )\n",
    "    _bar_metric_by_group(\n",
    "        y_true_test, y_pred_star, gs, f1_score, \"f1\", save_name=f\"bar_f1_by_{col}.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Confusion matrices by group + сохранение --- #\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "assert \"t_star\" in globals()\n",
    "assert all(k in globals() for k in [\"y_true_test\", \"y_proba_best\", \"X_test_sens\"])\n",
    "y_pred_star = (y_proba_best >= t_star).astype(int)\n",
    "\n",
    "\n",
    "def _plot_cm(y_true, y_pred, title=\"\"):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cbar=False, ax=ax)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticklabels([\"0\", \"1\"])\n",
    "    ax.set_yticklabels([\"0\", \"1\"])\n",
    "    return fig\n",
    "\n",
    "\n",
    "for col in [c for c in [\"sex\", \"race\", \"age_group\"] if c in X_test_sens.columns]:\n",
    "    s = X_test_sens[col]\n",
    "    for g in s.dropna().unique():\n",
    "        mask = (s == g).to_numpy()\n",
    "        if mask.sum() < 50:\n",
    "            continue\n",
    "        fig = _plot_cm(\n",
    "            y_true_test[mask], y_pred_star[mask], title=f\"CM: {col}={g} (n={mask.sum()})\"\n",
    "        )\n",
    "        safe_g = str(g).replace(\"/\", \"-\").replace(\"\\\\\", \"-\").replace(\" \", \"_\")\n",
    "        save_fig(f\"cm_{col}_{safe_g}.png\", fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Baselines visuals from figures_02 --- #\n",
    "\n",
    "figs02, dir02 = A[\"figures02\"]\n",
    "if figs02:\n",
    "    print(f\"[info] figures_02: {dir02} | count={len(figs02)}\")\n",
    "    for p in figs02[:6]:\n",
    "        print(\" -\", p.name)\n",
    "else:\n",
    "    print(\"[skip] figures_02 not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "# --- Explainability: глобально (SHAP / альтернативы) --- #\n",
    "\n",
    "**Цель.** Понять, какие признаки вносят наибольший вклад в предсказания модели и нет ли косвенных зависимостей от чувствительных характеристик.\n",
    "\n",
    "**Методика.** Для финальной модели (LightGBM/XGBoost) использован `shap.TreeExplainer`, позволяющий оценить вклад каждого признака в прогноз вероятности класса `>50k`. SHAP обеспечивает консистентную интерпретацию влияния признаков, что делает его предпочтительным методом для объяснимости бустинговых моделей.\n",
    "\n",
    "**Результаты глобального анализа:**\n",
    "1. Вклад ключевых социально-экономических признаков (например, `marital-status_Married-civ-spouse`, `education-num`, `capital-gain`, `hours-per-week`, `age`) значительно выше остальных.\n",
    "2. Чувствительные переменные (`sex`, `race`, `age_group`) имеют низкое среднее влияние, что говорит об отсутствии прямого использования этих признаков моделью.\n",
    "3. Однако частичные зависимости (через прокси-признаки вроде `occupation`, `marital-status`) могут опосредованно отражать различия между группами.\n",
    "\n",
    "**Вывод.** SHAP подтверждает, что модель в целом фокусируется на экономических и демографических характерисках, релевантных доходу, а не на чувствительных признаках напрямую. Это согласуется с результатами fairness-оценки, где наблюдались умеренные, но не критичные различия по группам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Explainability input selection via unified loader --- #\n",
    "\n",
    "assert \"A\" in globals(), \"Выполните unified loader\"\n",
    "model, _ = A[\"model\"]\n",
    "XS, _ = A[\"X_test_enc\"]\n",
    "feature_names, _ = A[\"feature_names\"]\n",
    "test_groups, _ = A[\"test_groups\"]\n",
    "\n",
    "# прямое использование загруженных артефактов #\n",
    "if XS is not None and feature_names is not None:\n",
    "    clf_for_shap = getattr(model, \"best_estimator_\", model)\n",
    "    msg_ok = (\n",
    "        f\"[ok] XS: {getattr(XS, 'shape', None)}, \"\n",
    "        f\"features: {len(feature_names)}, \"\n",
    "        f\"model: {type(clf_for_shap).__name__}\"\n",
    "    )\n",
    "    print(msg_ok)\n",
    "else:\n",
    "    # fallback только если что-то отсутствует\n",
    "    warn_msg = (\n",
    "        \"[warn] Нет XS или feature_names из артефактов. \"\n",
    "        \"Включено...fallback-восстановление \"\n",
    "        \"(отключено по политике unified loader).\"\n",
    "    )\n",
    "    print(warn_msg)\n",
    "    raise RuntimeError(\n",
    "        \"Отсутствуют необходимые артефакты для explainability: X_test_enc и/или feature_names.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dependence-plots для топ-фич --- #\n",
    "\n",
    "import re\n",
    "\n",
    "import scipy.sparse as sp\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# поиск артефактов во всех типичных папках проекта #\n",
    "ART_DIRS = [\n",
    "    Path(\"data\") / \"artifacts\",\n",
    "    Path(\"data\") / \"models\",\n",
    "    Path(\"notebooks\") / \"artifacts\",\n",
    "    Path(\"notebooks\") / \"models\",\n",
    "]\n",
    "\n",
    "\n",
    "def _first_exists_any(names):\n",
    "    names_lower = [n.lower() for n in names]\n",
    "    for d in ART_DIRS:\n",
    "        if not d.exists():\n",
    "            continue\n",
    "        for p in d.iterdir():\n",
    "            if p.is_file() and p.name.lower() in names_lower:\n",
    "                return p\n",
    "    # рекурсивный fallback\n",
    "    roots = [Path(\".\").resolve()]\n",
    "    roots += list(roots[0].parents)[:3]\n",
    "    for root in roots:\n",
    "        for p in root.rglob(\"*\"):\n",
    "            try:\n",
    "                if p.is_file() and p.name.lower() in names_lower:\n",
    "                    return p\n",
    "            except PermissionError:\n",
    "                continue\n",
    "    return None\n",
    "\n",
    "\n",
    "# модель #\n",
    "clf = None\n",
    "p_model = _first_exists_any([\"lgb_best.joblib\", \"LGBM_best.joblib\", \"model_best.joblib\"])\n",
    "if p_model is not None:\n",
    "    model, model_path = A[\"model\"]\n",
    "    obj = model\n",
    "    # если это pipeline — достанем из него clf\n",
    "    if hasattr(obj, \"named_steps\"):\n",
    "        clf = obj.named_steps.get(\"clf\", None) or obj\n",
    "    else:\n",
    "        clf = obj\n",
    "\n",
    "# данные: X_test_enc и feature_names #\n",
    "X_test_enc, X_test_enc_path = A[\"X_test_enc\"]\n",
    "XS = X_test_enc\n",
    "\n",
    "# загрузка feature_names из артефактов #\n",
    "feature_names, feature_names_path = A[\"feature_names\"]\n",
    "\n",
    "# защита от отсутствия данных #\n",
    "if XS is None:\n",
    "    print(\"Нет данных XS/X_test_enc: пропуск dependence-plots.\")\n",
    "    raise SystemExit\n",
    "\n",
    "# выравнивание feature_names под текущую матрицу XS #\n",
    "ncols = XS.shape[1]\n",
    "\n",
    "# попытка взять имена из модели (если не дефолтные f0..fN) #\n",
    "try:\n",
    "    if (\n",
    "        \"clf\" in globals()\n",
    "        and clf is not None\n",
    "        and hasattr(clf, \"booster_\")\n",
    "        and clf.booster_ is not None\n",
    "    ):\n",
    "        fnm = list(clf.booster_.feature_name())\n",
    "        all_fnums = all(isinstance(x, str) and re.fullmatch(r\"f\\d+\", x) for x in fnm)\n",
    "        if isinstance(fnm, list) and len(fnm) == ncols and not all_fnums:\n",
    "            feature_names = [str(x) for x in fnm]\n",
    "            print(\"[info] feature_names взяты из модели (booster).\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "\n",
    "# гарантия совпадения длины: обрезать/дополнить при необходимости #\n",
    "def _ensure_len(cols, n):\n",
    "    lst = list(cols) if isinstance(cols | list | np.ndarray | pd.Index) else []\n",
    "    if len(lst) == n:\n",
    "        return [str(c) for c in lst]\n",
    "    if len(lst) > n:\n",
    "        print(f\"[warn] feature_names длиннее ({len(lst)}) ncols={n}. Обрезаем.\")\n",
    "        return [str(c) for c in lst[:n]]\n",
    "    print(f\"[warn] feature_names короче ({len(lst)}) ncols={n}. Дополняем f{len(lst)}..f{n - 1}.\")\n",
    "    return [str(c) for c in (lst + [f\"f{i}\" for i in range(len(lst), n)])]\n",
    "\n",
    "\n",
    "if feature_names is None or (\n",
    "    isinstance(feature_names, list | np.ndarray | pd.Index) and len(feature_names) != ncols\n",
    "):\n",
    "    feature_names = _ensure_len(feature_names, ncols)\n",
    "\n",
    "if XS is not None and not isinstance(XS, pd.DataFrame):\n",
    "    if sp.issparse(XS):\n",
    "        XS = pd.DataFrame.sparse.from_spmatrix(\n",
    "            XS, columns=(feature_names if feature_names is not None else None)\n",
    "        )\n",
    "    else:\n",
    "        XS = pd.DataFrame(XS, columns=(feature_names if feature_names is not None else None))\n",
    "\n",
    "# выделение классификатора из pipeline при необходимости #\n",
    "clf_for_shap = None\n",
    "if \"clf\" in globals() and clf is not None and hasattr(clf, \"predict_proba\"):\n",
    "    clf_for_shap = clf\n",
    "else:\n",
    "    # безопасная проверка pipeline\n",
    "    g = globals()\n",
    "    _pipe = g.get(\"pipe\", None)\n",
    "\n",
    "    if (_pipe is not None) and hasattr(_pipe, \"named_steps\"):\n",
    "        steps = getattr(_pipe, \"named_steps\", {})\n",
    "        clf_for_shap = steps.get(\"clf\")\n",
    "        if clf_for_shap is None:\n",
    "            for _, step in steps.items():\n",
    "                if hasattr(step, \"predict_proba\") or hasattr(step, \"predict\"):\n",
    "                    clf_for_shap = step\n",
    "                    break\n",
    "\n",
    "# единая проверка и подвыборка #\n",
    "if clf_for_shap is None or XS is None:\n",
    "    print(\"Нет пригодной модели/данных для SHAP: пропуск dependence-plots.\")\n",
    "else:\n",
    "    # подвыборка\n",
    "    idx = np.arange(len(XS))\n",
    "    if len(idx) > 5000:\n",
    "        idx = rng.choice(idx, size=5000, replace=False)\n",
    "    XS_sub = XS.iloc[idx] if hasattr(XS, \"iloc\") else XS[idx, :]\n",
    "\n",
    "    expl = shap.TreeExplainer(clf_for_shap)\n",
    "    shap_vals = expl.shap_values(XS_sub)\n",
    "\n",
    "    # бинарный класс -> берем вклад позитивного класса\n",
    "    if isinstance(shap_vals, list):\n",
    "        try:\n",
    "            classes_ = getattr(clf_for_shap, \"classes_\", [0, 1])\n",
    "            pos_idx = list(classes_).index(1)\n",
    "        except Exception:\n",
    "            pos_idx = 1 if len(shap_vals) > 1 else 0\n",
    "        shap_vals = shap_vals[pos_idx]\n",
    "\n",
    "    # top-k\n",
    "    topk = 10\n",
    "\n",
    "    # beeswarm -> файл\n",
    "    shap.summary_plot(\n",
    "        shap_vals,\n",
    "        XS_sub,\n",
    "        feature_names=(feature_names if feature_names is not None else None),\n",
    "        show=False,\n",
    "        max_display=topk,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    save_fig(\"shap_summary_top10.png\", None)\n",
    "    plt.close()\n",
    "\n",
    "    # bar -> файл\n",
    "    shap.summary_plot(\n",
    "        shap_vals,\n",
    "        XS_sub,\n",
    "        feature_names=(feature_names if feature_names is not None else None),\n",
    "        plot_type=\"bar\",\n",
    "        show=False,\n",
    "        max_display=topk,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    save_fig(\"shap_bar_top10.png\", None)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Explainability: локально (кейсы TP/FP/FN) --- #\n",
    "\n",
    "assert all(k in globals() for k in [\"y_true_test\", \"y_proba_best\", \"X_test_sens\"])\n",
    "thr = globals().get(\"t_star\", 0.5)\n",
    "y_pred_thr = (y_proba_best >= thr).astype(\"int8\")\n",
    "\n",
    "TP_idx = np.where((y_true_test == 1) & (y_pred_thr == 1))[0]\n",
    "FP_idx = np.where((y_true_test == 0) & (y_pred_thr == 1))[0]\n",
    "FN_idx = np.where((y_true_test == 1) & (y_pred_thr == 0))[0]\n",
    "\n",
    "# только артефакты из unified loader #\n",
    "XS, _ = A[\"X_test_enc\"]\n",
    "feature_names, _ = A[\"feature_names\"]\n",
    "model, _ = A[\"model\"]\n",
    "\n",
    "# извлечение классификатора из best_estimator_/Pipeline #\n",
    "obj = getattr(model, \"best_estimator_\", model)\n",
    "if hasattr(obj, \"named_steps\"):\n",
    "    clf_for_shap = obj.named_steps.get(\"clf\", None)\n",
    "    if clf_for_shap is None:\n",
    "        for step in obj.named_steps.values():\n",
    "            if hasattr(step, \"predict_proba\") or hasattr(step, \"predict\"):\n",
    "                clf_for_shap = step\n",
    "                break\n",
    "else:\n",
    "    clf_for_shap = obj\n",
    "\n",
    "if clf_for_shap is None:\n",
    "    raise RuntimeError(\"Не удалось извлечь классификатор из Pipeline для SHAP.\")\n",
    "\n",
    "if XS is None and feature_names is None:\n",
    "    raise RuntimeError(\n",
    "        \"Нет X_test_enc или feature_names из артефактов; не выполняем explainability.\"\n",
    "    )\n",
    "\n",
    "# построение SHAP-графиков #\n",
    "expl = shap.TreeExplainer(clf_for_shap)\n",
    "\n",
    "\n",
    "def _pick_some(arr, k=3):\n",
    "    if len(arr) == 0:\n",
    "        return []\n",
    "    rng = np.random.default_rng(42)\n",
    "    return arr if len(arr) <= k else rng.choice(arr, size=k, replace=False).tolist()\n",
    "\n",
    "\n",
    "cases = [\n",
    "    (\"TP\", _pick_some(TP_idx, 3)),\n",
    "    (\"FP\", _pick_some(FP_idx, 3)),\n",
    "    (\"FN\", _pick_some(FN_idx, 3)),\n",
    "]\n",
    "\n",
    "for tag, idxs in cases:\n",
    "    if not idxs:\n",
    "        print(f\"{tag}: нет кейсов - пропуск.\")\n",
    "        continue\n",
    "    for i in idxs:\n",
    "        if hasattr(XS, \"iloc\"):\n",
    "            row = XS.iloc[[i]]\n",
    "        elif sp.issparse(XS):\n",
    "            row = XS[i]\n",
    "        else:\n",
    "            row = XS[i : i + 1]\n",
    "\n",
    "        sv = expl.shap_values(row)\n",
    "\n",
    "        # выбор класс и разжитие до 2D\n",
    "        sv_arr = sv[1] if isinstance(sv, list) else sv\n",
    "        if getattr(sv_arr, \"ndim\", 1) == 1:\n",
    "            sv_arr = sv_arr.reshape(1, -1)\n",
    "\n",
    "        # LightGBM: последний столбец = base value -> вынести и обрезать\n",
    "        if sv_arr.shape[1] == row.shape[1] + 1:\n",
    "            base_val = sv_arr[0, -1]\n",
    "            sv_arr = sv_arr[:, :-1]\n",
    "        else:\n",
    "            ev = expl.expected_value\n",
    "            base_val = ev[1] if isinstance(ev, list | np.ndarray) else ev\n",
    "\n",
    "        # признаки как 1D\n",
    "        if hasattr(row, \"values\"):  # DataFrame\n",
    "            feats_1d = row.values.reshape(-1)\n",
    "        else:  # np/sparse\n",
    "            feats_1d = np.asarray(row).reshape(-1)\n",
    "\n",
    "        fig = shap.force_plot(\n",
    "            base_value=base_val,\n",
    "            shap_values=sv_arr.reshape(-1),\n",
    "            features=feats_1d,\n",
    "            feature_names=feature_names,\n",
    "            matplotlib=True,\n",
    "            show=False,\n",
    "        )\n",
    "        plt.suptitle(f\"{tag} case idx={i} @ t={thr:.2f}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "# --- Риски, ограничения, рекомендации --- #\n",
    "\n",
    "**Качество и справедливость.** Финальная модель демонстрирует высокий уровень предсказательной способности (ROC-AUC около 0.9) при умеренном компромиссе между точностью и справедливостью. Без коррекции fairness наблюдается дисбаланс в доле положительных предсказанйи между полами, однако применение пост-обработки (ThresholdOptimizer с демографическим паритетом или равными шансами) значительно снижает разрыв. Это сопровождается небольшим падением F1-метрики - типичный эффект балансировки fairness и accuracy.\n",
    "\n",
    "**Калибровка и интерпретируемость.** Для крупных групп модель хорошо откалибрована: вероятности адекватно отражают реальные частоты положительного исхода. Для малых групп (по возрасту или редким рассовым категориям) погрешность выше, что объясняется ограниченным числом наблюдений. Глобальный SHAP-анализ подтверждает, что модель опирается прежде всего на социально-экономические признаки (`marital-status`, `education-num`, `capital-gain`, `hours-per-week`, `age`), а чувствительные признаки имеют минимальное прямое влияние.\n",
    "\n",
    "**Риски и направления улучшения:**\n",
    "1. Небольшие группы дают нестабильные fairness-метрики и ухудление калибровки.\n",
    "2. Возможные прокси-факторы (например, семейное положение или профессия) могут частично кодировать чувствительные характеристики.\n",
    "3. Усиление fairness-регуляции может привести к заметной потере точности.\n",
    "\n",
    "**Рекомендации:**\n",
    "1. Для практического использования целесообразно применять модель с базовым порогом `t=0.5` или оптимальным `t*`.\n",
    "2. В задачах с критичными требованиями к справедливости использовать ThresholdOptimizer с контролем демографического паритета.\n",
    "3. Проверить влияние или агрегации прокси-фичей на устойчивость fairness-метрик.\n",
    "4. При необходимости провести перекалибровку вероятностей (Platt или Isotonic) и расширить данные по малым подгруппам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Экспорт артефактов из 03_fairness_and_explainability.ipynb --- #\n",
    "\n",
    "ART_DIR = globals().get(\"ART_DIR\", Path(\"data\") / \"artifacts\")\n",
    "REPORTS_DIR = globals().get(\"REPORTS_DIR\", Path(\"data\") / \"reports\")\n",
    "\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(REPORTS_DIR / \"figures_03\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# экспорт сканирования порогов #\n",
    "scan_obj = globals().get(\"scan_df\", None)\n",
    "try:\n",
    "    if isinstance(scan_obj, pd.DataFrame) and len(scan_obj) > 0:\n",
    "        out_csv = ART_DIR / \"fairness_threshold_scan.csv\"\n",
    "        scan_obj.to_csv(out_csv, index=False)\n",
    "        print(f\"Saved fairness_threshold_scan.csv -> {out_csv}\")\n",
    "\n",
    "        # копия в reports для удобства просмотра\n",
    "        out_csv_rep = REPORTS_DIR / \"figures_03\" / \"fairness_threshold_scan.csv\"\n",
    "        try:\n",
    "            scan_obj.to_csv(out_csv_rep, index=False)\n",
    "            print(f\"Copied to reports -> {out_csv_rep}\")\n",
    "        except Exception as e:\n",
    "            print(\"[warn] copy to reports failed:\", e)\n",
    "    else:\n",
    "        print(\"[info] scan_df отсутствует или пуст - экспорт пропущен.\")\n",
    "except Exception as e:\n",
    "    print(\"[warn] scan_df export:\", e)\n",
    "\n",
    "print(\"Экспорт артефактов из 03_fairness_and_explainability.ipynb завершен.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Контроль готовности --- #\n",
    "\n",
    "# базовые директории #\n",
    "ROOT = globals().get(\"ROOT\", Path(\".\"))\n",
    "ART_DIR = globals().get(\"ART_DIR\", ROOT / \"data\" / \"artifacts\")\n",
    "REPORTS_DIR = globals().get(\"REPORTS_DIR\", ROOT / \"data\" / \"reports\")\n",
    "FIG_DIR_03 = REPORTS_DIR / \"figures_03\"\n",
    "\n",
    "# проверка наличия ключевых директорий #\n",
    "assert ART_DIR.exists(), f\"Нет папки артефактов: {ART_DIR}\"\n",
    "FIG_DIR_03.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# обязательные объекты в памяти #\n",
    "need = [\"feature_names\", \"X_test_enc\", \"sensitive\", \"y_true\", \"y_proba\", \"y_pred\"]\n",
    "miss = [k for k in need if (k not in A) or (A.get(k, (None, None))[0] is None)]\n",
    "if miss:\n",
    "    raise RuntimeError(f\"Не загружены артефакты {miss}\")\n",
    "\n",
    "# ожидаемые файлы и паттерны #\n",
    "critical = [\n",
    "    FIG_DIR_03 / \"fairness_threshold_scan.csv\",\n",
    "    ART_DIR / \"fairness_threshold_scan.csv\",\n",
    "    FIG_DIR_03 / \"shap_summary_top10.png\",\n",
    "    FIG_DIR_03 / \"shap_bar_top10.png\",\n",
    "    FIG_DIR_03 / \"group_metrics_t_star.csv\",\n",
    "    FIG_DIR_03 / \"selection_rates_t_star.csv\",\n",
    "]\n",
    "\n",
    "patterns = [\n",
    "    \"Pareto_f1_vs_dp.png\",\n",
    "    \"accuracy_f1_vs_threshold.png\",\n",
    "    \"dp_vs_threshold.png\",\n",
    "    \"eod_vs_threshold.png\",\n",
    "    \"calibration_*.png\",\n",
    "    \"bar_precision_by_*.png\",\n",
    "    \"bar_recall_by_*.png\",\n",
    "    \"bar_f1_by_*.png\",\n",
    "    \"cm_*_*.png\",\n",
    "]\n",
    "\n",
    "# проверка critical #\n",
    "missing_critical = [str(p) for p in critical if not Path(p).exists()]\n",
    "if missing_critical:\n",
    "    raise AssertionError(f\"Отсутствуют обязательные файлы: {missing_critical}\")\n",
    "\n",
    "# сводка по паттернам #\n",
    "summary = {}\n",
    "for pat in patterns:\n",
    "    files = list(FIG_DIR_03.glob(pat))\n",
    "    summary[pat] = len(files)\n",
    "\n",
    "# печать сводки #\n",
    "print(\"[fairness] report @\", FIG_DIR_03)\n",
    "for pat, cnt in summary.items():\n",
    "    print(f\"    {pat:28s} -> {cnt:3d}\")\n",
    "\n",
    "# дополнительная логика: предупреждения #\n",
    "warn = []\n",
    "\n",
    "# если есть чувствительные признаки, ожидаем как минимум по одному графику var_* #\n",
    "_sens_df = A.get(\"sensitive\", (globals().get(\"X_test_sensitive\", None), None))[0]\n",
    "present_cols = [\n",
    "    c for c in [\"sex\", \"race\", \"age_group\"] if (_sens_df is not None and c in _sens_df.columns)\n",
    "]\n",
    "for col in present_cols:\n",
    "    for base in [\"bar_precision_by_\", \"bar_recall_by_\", \"bar_f1_by_\"]:\n",
    "        if not list(FIG_DIR_03.glob(f\"{base}{col}.png\")):\n",
    "            warn.append(f\"Нет {base}{col}.png\")\n",
    "\n",
    "# хотя бы одна матрица ошибок #\n",
    "if summary.get(\"cm_*_*.png\", 0) == 0:\n",
    "    warn.append(\"Нет confusion matrices (cm_*_*.png)\")\n",
    "\n",
    "# хотя бы один calibration_*.png #\n",
    "if summary.get(\"calibration_*.png\", 0) == 0:\n",
    "    warn.append(\"Нет calibartion_*.png\")\n",
    "\n",
    "if warn:\n",
    "    print(\"[fairness][warn]\", \"; \".join(warn))\n",
    "else:\n",
    "    print(\"[fairness] OK: полный набор файлов сформирован.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "census_ds2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
