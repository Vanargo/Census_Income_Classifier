{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c3fc2e8",
   "metadata": {},
   "source": [
    "© 2025 Vanargo · Лицензия: MIT. См. файл `LICENSE` в корне репозитория."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feffc7c9",
   "metadata": {},
   "source": [
    "# --- 02. Modeling: Baselines, Tuning, Evaluation --- #\n",
    "\n",
    "**Цель ноутбука:** собрать воспроизводимый конвейер обучения для задачи 'income > 50K' на Adult (Census Income), сравнить модели, выбрать лучшую и сохранить артефакты для следующего этапа (03 - fairness & explainability).\n",
    "\n",
    "**Содержимое:**\n",
    "1. Загрузка подготовленного датасета (из 01_data_loading_and_eda.ipynb).\n",
    "2. Единый препроцессор (импутация, масштабирование, OHE).\n",
    "3. Модели: Logistic Regression -> Decision Tree -> Random Forest (baseline + tuning) -> XGBoost (early stopping) -> LightGBM (tuning).\n",
    "4. Единая таблица метрик + визуализация.\n",
    "5. Сохранение лучшей модели и артефакторв для 03 (fairness & explainability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e035f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорты и настройки моделинга #\n",
    "\n",
    "import warnings, logging, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from joblib import dump\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.model_selection import (train_test_split, StratifiedKFold,\n",
    "                                     RandomizedSearchCV)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score,\n",
    "                             recall_score, roc_auc_score, roc_curve,\n",
    "                             auc, precision_recall_curve,\n",
    "                             ConfusionMatrixDisplay, confusion_matrix,\n",
    "                             )\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb \n",
    "from IPython import get_ipython\n",
    "from pathlib import Path\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# тихие логгеры #\n",
    "logging.getLogger('lightgbm').setLevel(logging.ERROR)\n",
    "logging.getLogger('xgboost').setLevel(logging.ERROR)\n",
    "logging.getLogger('matplotlib').setLevel(logging.ERROR)\n",
    "logging.getLogger('numba').setLevel(logging.ERROR)\n",
    "\n",
    "# генератор случайности #\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# графики #\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c401230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Notebook preamble: silence & style --- #\n",
    "\n",
    "# красивые графики и кириллица без предупреждений о 'glyphs' #\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "\n",
    "# адресные централизованные фильтры предупреждений #\n",
    "warnings.filterwarnings('ignore', category=UserWarning,\n",
    "                        message='.*LightGBM binary classifier.*TreeExplainer.*')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning,\n",
    "                        message='.*Numpy global RNG was seeded.*')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning,\n",
    "                        message='.*is_categorical_dtype is deprecated.*')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning,\n",
    "                        message='.*pandas.*allow_gtml.*')\n",
    "warnings.filterwarnings('ignore', category=UserWarning,\n",
    "                        message='.*FixedFormatter should only be used with FixedLocator.*')\n",
    "warnings.filterwarnings('ignore', category=UserWarning,\n",
    "                        message='.*Glyph .* missing from current font.*')\n",
    "\n",
    "# полностью скрыть DeprecationWarning #\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# без спама от Jupyter магии autereload #\n",
    "ip = get_ipython()\n",
    "if ip:\n",
    "    try:\n",
    "        ip.run_line_magic('load_ext', 'autoreload')\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "326a9da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[paths] ROOT = C:\\Users\\UserHome\\Desktop\\PRCTC\\1. Census Income Classifier_v02\n"
     ]
    }
   ],
   "source": [
    "# --- Project paths bootstrip --- #\n",
    "\n",
    "# imports & paths #\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# предоставление Jupyter доступа к модулям из корня проекта #\n",
    "ROOT = Path.cwd()\n",
    "while not any((ROOT / m).exists() for m in ('.git', 'pyproject.toml', 'README.md')) and ROOT.parent != ROOT:\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))\n",
    "\n",
    "from paths import ROOT, DATA_DIR, RAW_DIR, INT_DIR, PROC_DIR, ART_DIR, REPORTS_DIR, MODELS_DIR, NB_DIR\n",
    "print(f'[paths] ROOT = {ROOT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b30f4c",
   "metadata": {},
   "source": [
    "# --- Data Split --- #\n",
    "\n",
    "**Задача:** загрузить финальный датасет после EDA, сформировать 'X/y', сделать стратифицированный train/test split и задать списки признаков (*'num_features'*, *'cat_features'*).\n",
    "\n",
    "**Важно:** все дальнейшие модели используют именно эти *'X_train/X_test/y_train/y_test',* и списки фичей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f31a67ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма полного набора: (48842, 18) | Классы: {0: 0.761, 1: 0.239}\n",
      "train: (39073, 18), test: (9769, 18) | pos_rate train=0.239, test=0.239\n",
      "num_features: 9 | cat_features: 9\n"
     ]
    }
   ],
   "source": [
    "# --- Загрузка EDA-датасета. Формирование X/y. train/test split --- #\n",
    "\n",
    "# пути #\n",
    "DATA_PROC_PARQUET = PROC_DIR / 'adult_eda.parquet'\n",
    "DATA_PROC_CSV = PROC_DIR / 'adult_eda.csv'\n",
    "\n",
    "# чтение (Parquet в приоритете, иначе CSV) #\n",
    "if DATA_PROC_PARQUET.exists():\n",
    "    df = pd.read_parquet(DATA_PROC_PARQUET)\n",
    "elif DATA_PROC_CSV.exists():\n",
    "    df = pd.read_csv(DATA_PROC_CSV)\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        'Не найден обработанный датасет в data/processed.'\n",
    "    )\n",
    "\n",
    "# базовые проверки #\n",
    "str_cols = [c for c in df.columns if df[c].dtype == 'object']\n",
    "if str_cols:\n",
    "    df[str_cols] = df[str_cols].apply(lambda s: s.str.strip())\n",
    "\n",
    "# цель и признаки #\n",
    "TARGET      = 'income_bin'\n",
    "drop_cols   = [TARGET, 'income']\n",
    "\n",
    "X = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
    "y = df[TARGET].astype(int)\n",
    "\n",
    "# sanity-check #\n",
    "assert set(np.unique(y)).issubset({0, 1}), 'y должен быть бинарным (0/1)'\n",
    "print('Форма полного набора:', X.shape, '| Классы:', y.value_counts(normalize=True).round(3).to_dict())\n",
    "\n",
    "# стратифицированный сплит #\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# список числовых/категориальных фич для препроцессинга #\n",
    "num_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_features = X_train.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# обеспечение категориального типа для биннинга возраста #\n",
    "for df_ in (X_train, X_test):\n",
    "    if 'age_group' in df_.columns:\n",
    "        df_.loc[:, 'age_group'] = df_['age_group'].astype('category')\n",
    "\n",
    "print(\n",
    "    f'train: {X_train.shape}, test: {X_test.shape} | '\n",
    "    f'pos_rate train={y_train.mean():.3f}, test={y_test.mean():.3f}'\n",
    ")\n",
    "print('num_features:', len(num_features), '| cat_features:', len(cat_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac83978",
   "metadata": {},
   "source": [
    "# --- Unified Preprocessing --- #\n",
    "\n",
    "**Идея:** один общий *'ColumnTransformer'* для всех моделей:\n",
    "1. **Числовые:** *\"SimpleImputer(strategy='median')\"* -> *'StandartScaler()'*.\n",
    "2. **Категориальные:** *\"SimpleImputer(strategy='most_frequent')\"* -> *\"OneHotEncoder(handle_unknown='ignore')\"*.\n",
    "\n",
    "Так мы гарантируем согласованность подготовки данных между моделями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e92931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Числовые: 9 | Категориальные: 9\n"
     ]
    }
   ],
   "source": [
    "# --- Базовый препроцессор (ColumnTransformer) для всех моделей --- #\n",
    "\n",
    "# числовой контейнер: median impute -> scale #\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# категориальный конвейер: fill 'Unknown' -> OHE #\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipeline, num_features),\n",
    "        ('cat', cat_pipeline, cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor.set_output(transform='pandas')\n",
    "\n",
    "print(f'Числовые: {len(num_features)} | Категориальные: {len(cat_features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec8dfda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Вспомогательные функции: метрики и логирование --- #\n",
    "\n",
    "def evaluate_model(model, X_tr, y_tr, X_te, y_te, name: str):\n",
    "    \"\"\"Возвращает dict с единым набором метрик\"\"\"\n",
    "    # вероятности для AUC (если есть predict_proba) #\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_proba_te = model.predict_proba(X_te)[:, 1]\n",
    "    else:\n",
    "        # fallback: решения некоторых моделей #\n",
    "        try:\n",
    "            y_proba_te = model.decision_function(X_te)\n",
    "        except Exception:\n",
    "            y_proba_te = None\n",
    "    \n",
    "    y_pred_te = model.predict(X_te)\n",
    "\n",
    "    metrics = {\n",
    "        'model': name,\n",
    "        'accuracy': accuracy_score(y_te,   y_pred_te),\n",
    "        'precision': precision_score(y_te,  y_pred_te,  zero_division=0),\n",
    "        'recall': recall_score(y_te,        y_pred_te,  zero_division=0),\n",
    "        'f1': f1_score(y_te,                y_pred_te,  zero_division=0),\n",
    "        'auc': roc_auc_score(y_te,          y_proba_te) if y_proba_te is not None else np.nan,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc9c6643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- инициализация хранилища результатов --- #\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b199e31",
   "metadata": {},
   "source": [
    "# --- Raw Copies for Analysis --- #\n",
    "\n",
    "Делаем копии \"сырых\" фичей (*'X_train_raw'*, *'X_test_raw'*) **до** конвейера. Это поможет при анализе ошибок/кейсов и при интерпретации в 03 - fairness & explainability (например, для групповых разрезов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf1865a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сырые данные: train_raw (39073, 18), test_raw (9769, 18)\n"
     ]
    }
   ],
   "source": [
    "# --- Создание raw-тестового набора и raw-тренировочного наборов --- #\n",
    "\n",
    "# копирование 'сырых' фич до конвейера (для интерпретации и анализа ошибок) #\n",
    "X_test_raw = X_test.copy()\n",
    "X_train_raw = X_train.copy()\n",
    "\n",
    "# age_group имеет категориальный тип #\n",
    "for df_ in (X_train_raw, X_test_raw):\n",
    "    if 'age_group' in df_.columns:\n",
    "        df_['age_group'] = df_['age_group'].astype('category')\n",
    "\n",
    "print(f'Сырые данные: train_raw {X_train_raw.shape}, test_raw {X_test_raw.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef417f",
   "metadata": {},
   "source": [
    "# --- Logistic Regression --- #\n",
    "\n",
    "Минимальный сильный baseline. Дает ориентир по качеству, обучается быстро, хорошо читает линейные зависимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c6721ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'LogReg',\n",
       " 'accuracy': 0.8554611526256526,\n",
       " 'precision': 0.740894901144641,\n",
       " 'recall': 0.6090675791274593,\n",
       " 'f1': 0.6685446009389672,\n",
       " 'auc': 0.9115962089316954}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Logistic Regression (baseline) --- #\n",
    "\n",
    "pipe_lr = Pipeline(steps=[\n",
    "    ('preproc', preprocessor),\n",
    "    ('clf',     LogisticRegression(\n",
    "        solver='lbfgs',\n",
    "        max_iter=2000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1 if 'n_jobs' in LogisticRegression().get_params() else None\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "metrics_lr = evaluate_model(pipe_lr, X_train, y_train, X_test, y_test, 'LogReg')\n",
    "results.append(metrics_lr)\n",
    "metrics_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ced6730",
   "metadata": {},
   "source": [
    "# --- Decision Tree --- #\n",
    "\n",
    "Показываем разницу Gini vs Entropy и фиксируем качество одиночного дерева. Полезно как интерпретируемый ориентир."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd9b5869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'DT_gini',\n",
       "  'accuracy': 0.8135940219060293,\n",
       "  'precision': 0.6086591004623791,\n",
       "  'recall': 0.6193327630453379,\n",
       "  'f1': 0.6139495442018232,\n",
       "  'auc': 0.7473975286062052},\n",
       " {'model': 'DT_entropy',\n",
       "  'accuracy': 0.8182004299314157,\n",
       "  'precision': 0.6189669771380186,\n",
       "  'recall': 0.6253207869974337,\n",
       "  'f1': 0.6221276595744681,\n",
       "  'auc': 0.7524539708863028}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Decision Tree: Gini vs Entropy --- #\n",
    "\n",
    "for crit in ['gini', 'entropy']:\n",
    "    pipe_dt = Pipeline(steps=[\n",
    "        ('preproc', preprocessor),\n",
    "        ('clf',     DecisionTreeClassifier(\n",
    "            criterion=crit,\n",
    "            max_depth=None,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    pipe_dt.fit(X_train, y_train)\n",
    "    results.append(evaluate_model(pipe_dt, X_train, y_train, X_test, y_test,\n",
    "                                  f'DT_{crit}'))\n",
    "results[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a289448e",
   "metadata": {},
   "source": [
    "# --- Random Forest --- #\n",
    "\n",
    "Сначала baseline, затем легкий *'RandomizedSearch'* по ключевым гиперпараметрам. Все варианты используют **единый** препроцессор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f898abc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'RF_baseline',\n",
       " 'accuracy': 0.8558706111167981,\n",
       " 'precision': 0.733433734939759,\n",
       " 'recall': 0.6248930710008554,\n",
       " 'f1': 0.6748267898383372,\n",
       " 'auc': 0.9086162124105213}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Random Forest: baseline --- #\n",
    "\n",
    "pipe_rf = Pipeline(steps=[\n",
    "    ('preproc', preprocessor),\n",
    "    ('clf',     RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "results.append(evaluate_model(pipe_rf, X_train, y_train, X_test, y_test,\n",
    "                              'RF_baseline'))\n",
    "results[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ea763a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF best params: {'clf__n_estimators': 400, 'clf__min_samples_split': 2, 'clf__min_samples_leaf': 2, 'clf__max_features': 'sqrt', 'clf__max_depth': 20} \n",
      "RF best CV AUC: 0.9191\n"
     ]
    }
   ],
   "source": [
    "# --- Random Forest: hyperparameter searh --- #\n",
    "\n",
    "rf_param_dist = {\n",
    "    'clf__n_estimators': [200, 400, 800],\n",
    "    'clf__max_depth': [None, 5, 10, 20],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__min_samples_leaf': [1, 2, 4],\n",
    "    'clf__max_features': ['sqrt', 'log2', 0.5, 0.8]\n",
    "}\n",
    "\n",
    "pipe_rf_tune = Pipeline(steps=[\n",
    "    ('prepr', preprocessor),\n",
    "    ('clf', RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rf_search = RandomizedSearchCV(\n",
    "    estimator=pipe_rf_tune,\n",
    "    param_distributions=rf_param_dist,\n",
    "    n_iter=20,\n",
    "    scoring='roc_auc',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42,\n",
    "    error_score=np.nan\n",
    ")\n",
    "rf_search.fit(X_train, y_train)\n",
    "print('RF best params:', rf_search.best_params_,\n",
    "      '\\nRF best CV AUC:', round(rf_search.best_score_, 4))\n",
    "\n",
    "rf_best = rf_search.best_estimator_\n",
    "results.append(evaluate_model(rf_best, X_train, y_train, X_test, y_test,\n",
    "                              'RF_best'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bc4a49",
   "metadata": {},
   "source": [
    "# --- XGBoost (Early Stopping) --- #\n",
    "\n",
    "Валидируем только на подвыборке из train. **Fit** препроцессора - на *'X_tr'*, далее только *'transform'* для *'X_val'* / *'X_test'*. Это исключает рассинхрон признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfcedf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best iteration: 365\n",
      "Best val AUC: 0.9312022415817004\n"
     ]
    }
   ],
   "source": [
    "# --- XGBoost: early stopping --- #\n",
    "\n",
    "# валид.сплит из train #\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "X_tr_enc =      preprocessor.fit_transform(X_tr)\n",
    "X_val_enc =     preprocessor.transform(X_val)\n",
    "X_te_enc =      preprocessor.transform(X_test)\n",
    "\n",
    "# sanity-check #\n",
    "assert X_tr_enc.shape[1] == X_val_enc.shape[1] == X_te_enc.shape[1], \\\n",
    "    f'Dim mismatch: train={X_tr_enc.shape[1]}, val={X_val_enc.shape[1]}, test={X_te_enc.shape[1]}'\n",
    "\n",
    "# DMatrix #\n",
    "dtr = xgb.DMatrix(X_tr_enc,     label=y_tr)\n",
    "dval = xgb.DMatrix(X_val_enc,   label=y_val)\n",
    "dte = xgb.DMatrix(X_te_enc)\n",
    "\n",
    "# параметры XGBoost #\n",
    "params = {\n",
    "    'objective':        'binary:logistic',\n",
    "    'eval_metric':      'auc',\n",
    "    'verbosity':        0,\n",
    "    'eta':              0.05,\n",
    "    'max_depth':        6,\n",
    "    'subsample':        0.9,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'seed':             42,\n",
    "    'tree_method':      'hist'\n",
    "}\n",
    "\n",
    "evals = [(dtr, 'train'), (dval, 'val')]\n",
    "\n",
    "# тренировка с ранней остановкой early stopping #\n",
    "bst = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtr,\n",
    "    num_boost_round=2000,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=False\n",
    ")\n",
    "\n",
    "print('Best iteration:',    bst.best_iteration)\n",
    "print('Best val AUC:',      bst.best_score)\n",
    "\n",
    "y_proba_xgb = bst.predict(dte, iteration_range=(0, bst.best_iteration + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6191f5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'XGB_es',\n",
       " 'accuracy': 0.8792097451120893,\n",
       " 'precision': 0.7951070336391437,\n",
       " 'recall': 0.6672369546621043,\n",
       " 'f1': 0.7255813953488373,\n",
       " 'auc': 0.9310527972257803}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Логирование метрик XGB --- #\n",
    "\n",
    "y_pred_xgb = (y_proba_xgb >= 0.5).astype(int)\n",
    "metrics_xgb = {\n",
    "    'model': 'XGB_es',\n",
    "    'accuracy': accuracy_score(y_test, y_pred_xgb),\n",
    "    'precision': precision_score(y_test, y_pred_xgb, zero_division=0),\n",
    "    'recall': recall_score(y_test, y_pred_xgb, zero_division=0),\n",
    "    'f1': f1_score(y_test, y_pred_xgb, zero_division=0),\n",
    "    'auc': roc_auc_score(y_test, y_proba_xgb)\n",
    "}\n",
    "results.append(metrics_xgb)\n",
    "metrics_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c71b3d",
   "metadata": {},
   "source": [
    "# --- LightGBM (RandomizedSearch) --- #\n",
    "\n",
    "Быстрый перебор по деревьям с использованием единого препроцессора. Метрика - ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c323030b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB best params: {'clf__subsample': 1.0, 'clf__num_leaves': 31, 'clf__min_child_samples': 20, 'clf__max_depth': 5, 'clf__learning_rate': 0.05, 'clf__colsample_bytree': 0.7} \n",
      "LGB best CV AUC: 0.9292\n"
     ]
    }
   ],
   "source": [
    "# --- LightGBM: RandomizedSearch --- #\n",
    "\n",
    "pipe_lgb = Pipeline(steps=[\n",
    "    ('preproc', preprocessor),\n",
    "    ('clf', lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        random_state=42,\n",
    "        n_estimators=500,\n",
    "        verbosity=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_dist_lgb = {\n",
    "    'clf__num_leaves':          [31, 63, 127, 255],\n",
    "    'clf__max_depth':           [-1, 5, 10, 20],\n",
    "    'clf__learning_rate':       [0.01, 0.05, 0.1],\n",
    "    'clf__subsample':           [0.7, 0.85, 1.0],\n",
    "    'clf__colsample_bytree':    [0.7, 0.85, 1.0],\n",
    "    'clf__min_child_samples':   [10, 20, 50, 100]\n",
    "}\n",
    "\n",
    "lgb_search = RandomizedSearchCV(\n",
    "    estimator=pipe_lgb,\n",
    "    param_distributions=param_dist_lgb,\n",
    "    n_iter=25,\n",
    "    scoring='roc_auc',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=42,\n",
    "    error_score=np.nan\n",
    ")\n",
    "\n",
    "lgb_search.fit(X_train, y_train)\n",
    "print('LGB best params:', lgb_search.best_params_, '\\nLGB best CV AUC:', round(lgb_search.best_score_, 4))\n",
    "\n",
    "lgb_best = lgb_search.best_estimator_\n",
    "results.append(evaluate_model(lgb_best, X_train, y_train, X_test, y_test,\n",
    "                              'LGBM_best'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe97b41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM train AUC: 0.9458\n",
      "LGBM test AUC: 0.9321\n",
      "Разрыв (train - test): +0.0136\n"
     ]
    }
   ],
   "source": [
    "# --- Разрыв train vs test для LGBM --- #\n",
    "\n",
    "# AUC на train #\n",
    "train_proba = lgb_best.predict_proba(X_train)[:, 1]\n",
    "auc_train = roc_auc_score(y_train, train_proba)\n",
    "\n",
    "# AUC на test #\n",
    "test_proba = lgb_best.predict_proba(X_test)[:, 1]\n",
    "auc_test = roc_auc_score(y_test, test_proba)\n",
    "\n",
    "print(f'LGBM train AUC: {auc_train:.4f}')\n",
    "print(f'LGBM test AUC: {auc_test:.4f}')\n",
    "print(f'Разрыв (train - test): {auc_train - auc_test:+.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5432d71e",
   "metadata": {},
   "source": [
    "# --- Unified Metrics Table --- #\n",
    "\n",
    "Все модели сводим в единый *'results_df'* (AUC, F1, Precision, Recall, Accuracy), сортируем по AUC/F1 и выбираем победителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ea380c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM_best</td>\n",
       "      <td>0.932137</td>\n",
       "      <td>0.723792</td>\n",
       "      <td>0.796915</td>\n",
       "      <td>0.662960</td>\n",
       "      <td>0.878903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGB_es</td>\n",
       "      <td>0.931053</td>\n",
       "      <td>0.725581</td>\n",
       "      <td>0.795107</td>\n",
       "      <td>0.667237</td>\n",
       "      <td>0.879210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF_best</td>\n",
       "      <td>0.921436</td>\n",
       "      <td>0.683694</td>\n",
       "      <td>0.802768</td>\n",
       "      <td>0.595381</td>\n",
       "      <td>0.868154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.911596</td>\n",
       "      <td>0.668545</td>\n",
       "      <td>0.740895</td>\n",
       "      <td>0.609068</td>\n",
       "      <td>0.855461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF_baseline</td>\n",
       "      <td>0.908616</td>\n",
       "      <td>0.674827</td>\n",
       "      <td>0.733434</td>\n",
       "      <td>0.624893</td>\n",
       "      <td>0.855871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DT_entropy</td>\n",
       "      <td>0.752454</td>\n",
       "      <td>0.622128</td>\n",
       "      <td>0.618967</td>\n",
       "      <td>0.625321</td>\n",
       "      <td>0.818200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DT_gini</td>\n",
       "      <td>0.747398</td>\n",
       "      <td>0.613950</td>\n",
       "      <td>0.608659</td>\n",
       "      <td>0.619333</td>\n",
       "      <td>0.813594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model       auc        f1  precision    recall  accuracy\n",
       "0    LGBM_best  0.932137  0.723792   0.796915  0.662960  0.878903\n",
       "1       XGB_es  0.931053  0.725581   0.795107  0.667237  0.879210\n",
       "2      RF_best  0.921436  0.683694   0.802768  0.595381  0.868154\n",
       "3       LogReg  0.911596  0.668545   0.740895  0.609068  0.855461\n",
       "4  RF_baseline  0.908616  0.674827   0.733434  0.624893  0.855871\n",
       "5   DT_entropy  0.752454  0.622128   0.618967  0.625321  0.818200\n",
       "6      DT_gini  0.747398  0.613950   0.608659  0.619333  0.813594"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Метрики и сводная таблица результатов --- #\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df[['model', 'auc', 'f1', 'precision', 'recall',\n",
    "                         'accuracy']]\n",
    "results_df.sort_values(by=['auc', 'f1'], ascending=False, inplace=True)\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fcbe2f",
   "metadata": {},
   "source": [
    "# --- Model Comparison Chart --- #\n",
    "\n",
    "Быстрый бар-чарт по ключевым метрикам  (AUC, F1, Accuracy) для визуального сравнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47c0d5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Визуализация сравнения моделей --- #\n",
    "\n",
    "ax = results_df.set_index('model')[['auc', 'f1', 'accuracy']].plot(kind='bar',\n",
    "                                                                   figsize=(10,5))\n",
    "ax.set_ylabel('score')\n",
    "ax.set_title('Model comparison (AUC, F1, Accuracy)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66ed3a",
   "metadata": {},
   "source": [
    "# --- Saving Best Model & Artifacts --- #\n",
    "\n",
    "Сохраняем лучшую модель и артефакты, чтобы в 03 (fairness & explainability) можно было:\n",
    "1. Загрузить модель.\n",
    "2. Получить предсказания/скоринги.\n",
    "3. Сделать fairness-анализ и интерпретацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92e3a5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший по AUC/F1: LGBM_best\n",
      "Сохранено: C:\\Users\\UserHome\\Desktop\\PRCTC\\1. Census Income Classifier_v02\\data\\models\\LGBM_best.joblib\n"
     ]
    }
   ],
   "source": [
    "# --- Сохранение лучшей модели --- #\n",
    "\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "best_row = results_df.iloc[0]\n",
    "best_name = best_row['model']\n",
    "print('Лучший по AUC/F1:', best_name)\n",
    "\n",
    "# соответствующий объект #\n",
    "name2obj = {\n",
    "    'LogReg': pipe_lr,\n",
    "    'DT_gini': None,\n",
    "    'DT_entropy': None,\n",
    "    'RF_baseline': pipe_rf,\n",
    "    'RF_best': rf_best,\n",
    "    'XGB_es': bst,\n",
    "    'LGBM_best': lgb_best,\n",
    "}\n",
    "\n",
    "obj = name2obj.get(best_name)\n",
    "if obj is not None and best_name != 'XGB_es':\n",
    "    dump(obj, MODELS_DIR / f'{best_name}.joblib')\n",
    "    print('Сохранено:', MODELS_DIR / f'{best_name}.joblib')\n",
    "elif best_name == 'XGB_es':\n",
    "    bst.save_model(str(MODELS_DIR / 'XGB_es.json'))\n",
    "    print('Сохранено', MODELS_DIR / 'XGB_es.json')\n",
    "else:\n",
    "    print('Добавь объект модели в name2obj перед сохранением.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fcf298",
   "metadata": {},
   "source": [
    "# --- Export Artifacts for 03 (fairness & explainability) --- #\n",
    "\n",
    "Сохраняем все, что понадобится в следующем ноутбуке:\n",
    "1. *'results_fd'* - сводная таблица по моделям.\n",
    "2. *'y_true_test'*, *'y_proba_test'*, *'y_pred_test'* - истинные и предсказанные значения на тесте.\n",
    "3. *'y_test_raw'* с чувствительными признаками (*'sex'*, *'race'*, *'age_group'*, *'education'*,,и т.д.)\n",
    "4. Технические артефакты: лучшая модель, препроцессор, имена фич после OHE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce04b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший по метрикам:  LGBM_best\n",
      "feature_names.npy saved\n",
      "Saved data\\artifacts\\X_test_enc.npy shape (9769, 115)\n",
      "Экспорт для 03_fairness_and_explainability.ipynb завершен.\n",
      "Файлы в artifacts: ['X_test_enc.npy', 'X_test_sensitive.csv', 'feature_names.npy', 'lgb_best.joblib', 'results_df.csv', 'test_groups.csv', 'y_pred_050.npy', 'y_pred_best.npy', 'y_proba_best.npy', 'y_score.npy', 'y_test.npy', 'y_true_test.npy']\n",
      "Saved: data\\artifacts\\lgb_best.joblib\n"
     ]
    }
   ],
   "source": [
    "# --- Экспорт артефактов --- #\n",
    "\n",
    "# сохранение сводной таблицы метрик #\n",
    "assert 'results_df' in globals(), 'results_df не найден. Сначала сформируйте таблицу метрик.'\n",
    "results_df.to_csv(ART_DIR / 'results_df.csv', index=False)\n",
    "\n",
    "# определить лучшую модель по AUC, затем F1 #\n",
    "best_row = results_df.sort_values(['auc', 'f1'], ascending=False).iloc[0]\n",
    "best_name = best_row['model']\n",
    "print('Лучший по метрикам: ', best_name)\n",
    "\n",
    "# y_true #\n",
    "assert 'y_test' in globals(), 'y_test не найден.'\n",
    "y_true_test = np.asarray(y_test, dtype='int8')\n",
    "\n",
    "# заглушки #\n",
    "y_proba_best: np.ndarray | None = None\n",
    "y_pred_best:  np.ndarray | None = None\n",
    "feature_names = None\n",
    "X_test_enc = None\n",
    "preproc_fitted = None\n",
    "\n",
    "# универсальный поиск preprocessor и имty признаков #\n",
    "def _find_preprocessor_from_pipeline(pipe):\n",
    "    if not hasattr(pipe, 'named_steps'):\n",
    "        return None\n",
    "    for key in ['preproc', 'prep', 'transformer', 'ct']:\n",
    "        if key in pipe.named_steps:\n",
    "            return pipe.named_steps[key]\n",
    "    return None\n",
    "\n",
    "candidate_pipes = []\n",
    "for nm in ['model_best', 'pipe_lr', 'pipe_rf', 'pipe_xgb']:\n",
    "    if nm in globals() and getattr(globals()[nm], 'named_steps', None):\n",
    "        candidate_pipes.append(globals()[nm])\n",
    "\n",
    "# попытка достать preprocessor из любого доступного pipeline #\n",
    "for p in candidate_pipes:\n",
    "    preproc_fitted = _find_preprocessor_from_pipeline(p)\n",
    "    if preproc_fitted is not None:\n",
    "        break\n",
    "\n",
    "# получение вероятностей/предсказаний лучшей модели #\n",
    "assert 'X_train' in globals() and 'X_test' in globals() and 'y_train' in globals(), \\\n",
    "    'Нужны X_train, X_test, y_train.'\n",
    "\n",
    "if best_name == 'XGB_es':\n",
    "    # XGBoost с ранней остановкой - ожидается booster bst\n",
    "    if 'bst' not in globals():\n",
    "        raise RuntimeError('Booster \"bst\" не найден. Выполните ячейку с XGBoost (early stopping).')\n",
    "\n",
    "    # для стабильности 03_fairness_and_explainability.ipynb:\n",
    "    # кодирование X_test, если есть preprocessor\n",
    "    try:\n",
    "        if preproc_fitted is None and 'model_best' in globals():\n",
    "            preproc_fitted = _find_preprocessor_from_pipeline(model_best)\n",
    "        if preproc_fitted is not None:\n",
    "            preproc_fitted = preproc_fitted.fit(X_train, y_train)  # зафиксируем состояние\n",
    "            X_test_enc = preproc_fitted.transform(X_test)\n",
    "    except Exception as e:\n",
    "        print(\"[warn] Не удалось получить X_test_enc для XGB_es:\", e)\n",
    "\n",
    "    # Если есть закодированный X — используем его; иначе пробуем сырые (если обучали так же)\n",
    "    try:\n",
    "        import xgboost as xgb\n",
    "        if X_test_enc is not None:\n",
    "            dte = xgb.DMatrix(X_test_enc)\n",
    "        else:\n",
    "            dte = xgb.DMatrix(X_test)\n",
    "        y_proba_best = bst.predict(dte, iteration_range=(0, bst.best_iteration + 1))\n",
    "        y_pred_best = (y_proba_best >= 0.5).astype('int8')\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f'Ошибка предсказания XGB_es: {e}')\n",
    "\n",
    "else:\n",
    "    # -------------------------------\n",
    "    # Фрагмент 4 — маппинг моделей для best_name (добавь сюда реально обученные в ноутбуке объекты)\n",
    "    # -------------------------------\n",
    "    name2obj = {\n",
    "        'LogReg'     : globals().get('pipe_lr'),\n",
    "        'DT_gini'    : None,      # чистое дерево обычно не сохраняем/не используем для финала\n",
    "        'DT_entropy' : None,\n",
    "        'RF_baseline': globals().get('pipe_rf'),\n",
    "        'RF_best'    : globals().get('rf_best'),\n",
    "        'LGBM_best'  : globals().get('lgb_best'),\n",
    "        'XGB_es'     : None,      # для XGB_es выше отдельная ветка\n",
    "    }\n",
    "    best_model = name2obj.get(best_name)\n",
    "    if best_model is None:\n",
    "        raise RuntimeError(\n",
    "            f'Нет обученного объекта модели для \"{best_name}\". '\n",
    "            f'Убедитесь, что соответствующая ячейка обучения выполнена и добавьте её в name2obj.'\n",
    "        )\n",
    "\n",
    "    # Вероятности/decision_function (работает и для Pipeline, и для чистого эстиматора)\n",
    "    if hasattr(best_model, 'predict_proba'):\n",
    "        y_proba_best = best_model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        if hasattr(best_model, 'decision_function'):\n",
    "            y_proba_best = best_model.decision_function(X_test)\n",
    "        else:\n",
    "            raise RuntimeError(f'Модель \"{best_name}\" не предоставляет вероятности/decision_function.')\n",
    "\n",
    "    y_pred_best = (y_proba_best >= 0.5).astype('int8')\n",
    "\n",
    "    # -------------------------------\n",
    "    # Фиксация препроцессора и подготовка X_test_enc (универсально)\n",
    "    # -------------------------------\n",
    "    # если best_model — это Pipeline, попробуем достать из него препроцессор\n",
    "    if getattr(best_model, \"named_steps\", None):\n",
    "        preproc_fitted = _find_preprocessor_from_pipeline(best_model)\n",
    "    # если не нашли, используем ранее найденный из candidate_pipes\n",
    "    if preproc_fitted is None:\n",
    "        preproc_fitted = None\n",
    "        for p in candidate_pipes:\n",
    "            preproc_fitted = _find_preprocessor_from_pipeline(p)\n",
    "            if preproc_fitted is not None:\n",
    "                break\n",
    "\n",
    "    # -------------------------------\n",
    "    # Фрагмент 2 — подготовка X_test_enc (с фолбэком на XS)\n",
    "    # -------------------------------\n",
    "    try:\n",
    "        if preproc_fitted is not None:\n",
    "            preproc_fitted = preproc_fitted.fit(X_train, y_train)\n",
    "            X_test_enc = preproc_fitted.transform(X_test)\n",
    "    except Exception as e:\n",
    "        print('[warn] transform(X_test) failed via preproc_fitted:', e)\n",
    "\n",
    "    if X_test_enc is None and 'XS' in globals():\n",
    "        X_test_enc = XS  # если где-то ранее уже готовили закодированную матрицу\n",
    "\n",
    "# sanity-check\n",
    "assert y_proba_best is not None and y_pred_best is not None, 'Не удалось получить предсказания модели.'\n",
    "\n",
    "# Чувствительные признаки для fairness-разрезов\n",
    "if 'X_test_raw' in globals():\n",
    "    sens_cols = [c for c in ['sex', 'race', 'age_group', 'education'] if c in X_test_raw.columns]\n",
    "    if sens_cols:\n",
    "        X_test_sens = X_test_raw[sens_cols].copy()\n",
    "        X_test_sens.to_csv(ART_DIR / 'X_test_sensitive.csv', index=False)\n",
    "\n",
    "# -------------------------------\n",
    "# Фрагмент 1 (продолжение) — попытка получить feature_names\n",
    "# -------------------------------\n",
    "def _try_get_feature_names(transformer):\n",
    "    # 1) Универсальный путь (sklearn >= 1.0)\n",
    "    try:\n",
    "        if transformer is not None and hasattr(transformer, 'get_feature_names_out'):\n",
    "            return transformer.get_feature_names_out()\n",
    "    except Exception:\n",
    "        pass\n",
    "    # 2) Попытка через составные трансформеры (ColumnTransformer с OneHot внутри)\n",
    "    try:\n",
    "        if transformer is not None and hasattr(transformer, 'named_transformers_'):\n",
    "            # наиболее частый кейс: 'cat' с OHE и какие-то числовые\n",
    "            cat = transformer.named_transformers_.get('cat') or transformer.named_transformers_.get('ohe')\n",
    "            if cat is not None:\n",
    "                ohe = getattr(cat, 'named_steps', {}).get('ohe', None)\n",
    "                if ohe is not None and hasattr(ohe, 'get_feature_names_out'):\n",
    "                    # Если есть num_features/cat_features в окружении — попробуем склеить; обернём в try\n",
    "                    names_num = []\n",
    "                    try:\n",
    "                        if 'num_features' in globals() and globals()['num_features'] is not None:\n",
    "                            names_num = list(globals()['num_features'])\n",
    "                    except Exception:\n",
    "                        names_num = []\n",
    "                    try:\n",
    "                        names_cat = list(ohe.get_feature_names_out())\n",
    "                    except Exception:\n",
    "                        names_cat = []\n",
    "                    if names_num or names_cat:\n",
    "                        return np.array(list(names_num) + list(names_cat))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "feature_names = _try_get_feature_names(preproc_fitted)\n",
    "\n",
    "# -------------------------------\n",
    "# Фрагмент 3 — сохранение feature names и X_test_enc (только если есть)\n",
    "# -------------------------------\n",
    "if feature_names is not None:\n",
    "    try:\n",
    "        np.save(ART_DIR / 'feature_names.npy', feature_names)\n",
    "        print('feature_names.npy saved')\n",
    "    except Exception as e:\n",
    "        print('[warn] feature_names.npy save failed:', e)\n",
    "\n",
    "if X_test_enc is not None:\n",
    "    try:\n",
    "        if sp.issparse(X_test_enc):\n",
    "            sp.save_npz(ART_DIR / 'X_test_enc.npz', X_test_enc)\n",
    "            print('Saved', ART_DIR / 'X_test_enc.npz', 'shape', X_test_enc.shape)\n",
    "        else:\n",
    "            np.save(ART_DIR / 'X_test_enc.npy', X_test_enc)\n",
    "            print('Saved', ART_DIR / 'X_test_enc.npy', 'shape', np.asarray(X_test_enc).shape)\n",
    "    except Exception as e:\n",
    "        print('[warn] X_test_enc save failed:', e)\n",
    "else:\n",
    "    # это не ошибка: 03 сможет работать по y_proba_best/y_true_test без X_test_enc\n",
    "    print('[info] X_test_enc не сформирован (препроцессор недоступен). Пропускаем сохранение.')\n",
    "\n",
    "# Бинарные артефакты предсказаний\n",
    "np.save(ART_DIR / 'y_true_test.npy', y_test)\n",
    "np.save(ART_DIR / 'y_proba_best.npy', y_proba_best)\n",
    "np.save(ART_DIR / 'y_pred_best.npy', y_pred_best)\n",
    "\n",
    "print('Экспорт для 03_fairness_and_explainability.ipynb завершен.')\n",
    "\n",
    "# Печать списка файлов (без падений, если что-то недоступно)\n",
    "try:\n",
    "    print('Файлы в artifacts:', sorted(p.name for p in ART_DIR.iterdir()))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# -------------------------------\n",
    "# Фрагмент 5 — сохранение lgb_best.joblib (только если объект есть)\n",
    "# -------------------------------\n",
    "try:\n",
    "    if 'lgb_best' in globals() and globals()['lgb_best'] is not None:\n",
    "        dump(lgb_best, ART_DIR / 'lgb_best.joblib')\n",
    "        print('Saved:', ART_DIR / 'lgb_best.joblib')\n",
    "except Exception as e:\n",
    "    print('[warn] lgb_best не удалось сохранить:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8c6348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] Exported: roc_curve.png, pr_curve.png, calibration_curve.png, confusion_matrix.png, feature_importance_lgbm.png (if LGBM), feature_importance_xgb_gain.png (if XGB).\n"
     ]
    }
   ],
   "source": [
    "# --- Export figures (ROC/PR/Calibration/Confusion/Feature importance) --- #\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix\n",
    "from sklearn.calibration import calibration_curve\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Папки вывода\n",
    "FIG_DIR = ROOT / 'reports' / 'figures_02'\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- 1) Надёжная загрузка y_true / y_proba / y_pred ----------\n",
    "g = globals()\n",
    "y_true = g.get(\"y_true_test\", g.get(\"y_test\", None))\n",
    "y_proba = g.get(\"y_proba_best\", None)\n",
    "y_pred  = g.get(\"y_pred_best\", None)\n",
    "\n",
    "# Fallback: загрузим из артефактов, если в памяти нет\n",
    "def _maybe_load(p):\n",
    "    try:\n",
    "        return np.load(p)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "if y_true is None and (ART_DIR / \"y_true_test.npy\").exists():\n",
    "    y_true = _maybe_load(ART_DIR / \"y_true_test.npy\")\n",
    "if y_proba is None and (ART_DIR / \"y_proba_best.npy\").exists():\n",
    "    y_proba = _maybe_load(ART_DIR / \"y_proba_best.npy\")\n",
    "if y_pred is None and (ART_DIR / \"y_pred_best.npy\").exists():\n",
    "    y_pred = _maybe_load(ART_DIR / \"y_pred_best.npy\")\n",
    "\n",
    "if y_true is None or y_proba is None:\n",
    "    raise RuntimeError(\"[export-figures] Нужны y_true и y_proba. Убедись, что предыдущая ячейка экспортов отработала.\")\n",
    "\n",
    "# если метки не загружены — восстановим их по порогу 0.5\n",
    "if y_pred is None or len(y_pred) != len(y_true):\n",
    "    y_pred = (y_proba >= 0.5).astype(\"int8\")\n",
    "\n",
    "# ---------- 2) ROC ----------\n",
    "fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, lw=2, label=f\"ROC AUC = {roc_auc:.4f}\")\n",
    "plt.plot([0,1], [0,1], lw=1, linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"roc_curve.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# ---------- 3) PR ----------\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, lw=2, label=f\"PR AUC = {pr_auc:.4f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"pr_curve.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# ---------- 4) Calibration ----------\n",
    "# n_bins можно подвинуть при необходимости\n",
    "prob_true, prob_pred = calibration_curve(y_true, y_proba, n_bins=10, strategy=\"uniform\")\n",
    "plt.figure()\n",
    "plt.plot(prob_pred, prob_true, marker=\"o\", lw=2, label=\"Calibration\")\n",
    "plt.plot([0,1], [0,1], linestyle=\"--\", lw=1, label=\"Perfect\")\n",
    "plt.xlabel(\"Mean predicted probability\")\n",
    "plt.ylabel(\"Fraction of positives\")\n",
    "plt.title(\"Calibration Curve\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"calibration_curve.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# ---------- 5) Confusion Matrix (threshold=0.5) ----------\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "plt.figure()\n",
    "plt.imshow(cm, interpolation=\"nearest\")\n",
    "plt.title(\"Confusion Matrix (thr=0.5)\")\n",
    "plt.xticks([0,1], [\"0\", \"1\"])\n",
    "plt.yticks([0,1], [\"0\", \"1\"])\n",
    "for (i, j), v in np.ndenumerate(cm):\n",
    "    plt.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"confusion_matrix.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# ---------- 6) Feature Importance (LGBM + XGB gain, если доступны) ----------\n",
    "# Попробуем достать имена признаков\n",
    "feature_names = None\n",
    "# 1) Из artifacts\n",
    "p_fn = ART_DIR / \"feature_names.npy\"\n",
    "if p_fn.exists():\n",
    "    try:\n",
    "        feature_names = np.load(p_fn, allow_pickle=True)\n",
    "    except Exception:\n",
    "        feature_names = None\n",
    "\n",
    "# 2) Из доступного препроцессора\n",
    "def _get_preproc_from_pipe(pipe):\n",
    "    if not hasattr(pipe, \"named_steps\"):\n",
    "        return None\n",
    "    for k in [\"preproc\", \"prep\", \"transformer\", \"ct\"]:\n",
    "        if k in pipe.named_steps:\n",
    "            return pipe.named_steps[k]\n",
    "    return None\n",
    "\n",
    "preproc = None\n",
    "for cand in [\"model_best\", \"pipe_lr\", \"pipe_rf\", \"pipe_xgb\"]:\n",
    "    if cand in g and hasattr(g[cand], \"named_steps\"):\n",
    "        preproc = _get_preproc_from_pipe(g[cand])\n",
    "        if preproc is not None:\n",
    "            break\n",
    "\n",
    "if feature_names is None and preproc is not None and hasattr(preproc, \"get_feature_names_out\"):\n",
    "    try:\n",
    "        feature_names = preproc.get_feature_names_out()\n",
    "    except Exception:\n",
    "        feature_names = None\n",
    "\n",
    "# ---------- 6a) LGBM ----------\n",
    "lgb_model = g.get(\"lgb_best\", None)\n",
    "if lgb_model is not None and hasattr(lgb_model, \"feature_importances_\"):\n",
    "    try:\n",
    "        imp = np.array(lgb_model.feature_importances_, dtype=float)\n",
    "        if feature_names is None or len(feature_names) != len(imp):\n",
    "            feat = np.array([f\"f{i}\" for i in range(len(imp))])\n",
    "        else:\n",
    "            feat = np.array(feature_names)\n",
    "        order = np.argsort(imp)[::-1][:40]  # top-40 для читаемости\n",
    "        plt.figure(figsize=(8, max(4, len(order) * 0.25)))\n",
    "        plt.barh(range(len(order)), imp[order][::-1])\n",
    "        plt.yticks(range(len(order)), feat[order][::-1])\n",
    "        plt.xlabel(\"Importance (split/gain depending on model)\")\n",
    "        plt.title(\"Feature Importance — LightGBM\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIG_DIR / \"feature_importance_lgbm.png\", dpi=200)\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(\"[warn] LGBM FI export:\", e)\n",
    "\n",
    "# ---------- 6b) XGB (gain) ----------\n",
    "# Вариант 1: прямой Booster 'bst'\n",
    "bst = g.get(\"bst\", None)\n",
    "got_xgb = False\n",
    "if bst is not None:\n",
    "    try:\n",
    "        fscore = bst.get_score(importance_type=\"gain\")  # dict: feat_name -> gain\n",
    "        if len(fscore) > 0:\n",
    "            # XGBoost обычно именует фичи как f0, f1, ...\n",
    "            items = sorted(fscore.items(), key=lambda kv: kv[1], reverse=True)[:40]\n",
    "            names = [k for k, _ in items]\n",
    "            gains = [v for _, v in items]\n",
    "            # Переименование, если есть feature_names и длины совпадают\n",
    "            def _map_name(raw):\n",
    "                if raw.startswith(\"f\") and raw[1:].isdigit():\n",
    "                    idx = int(raw[1:])\n",
    "                    if feature_names is not None and idx < len(feature_names):\n",
    "                        return str(feature_names[idx])\n",
    "                return raw\n",
    "            names = [_map_name(n) for n in names]\n",
    "            plt.figure(figsize=(8, max(4, len(names) * 0.25)))\n",
    "            plt.barh(range(len(names)), gains[::-1])\n",
    "            plt.yticks(range(len(names)), names[::-1])\n",
    "            plt.xlabel(\"Gain\")\n",
    "            plt.title(\"Feature Importance — XGBoost (gain)\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(FIG_DIR / \"feature_importance_xgb_gain.png\", dpi=200)\n",
    "            plt.close()\n",
    "            got_xgb = True\n",
    "    except Exception as e:\n",
    "        print(\"[warn] XGB Booster FI export:\", e)\n",
    "\n",
    "# Вариант 2: через sklearn XGBClassifier, если Booster отсутствует\n",
    "if not got_xgb:\n",
    "    # попробуем достать clf из пайплайна\n",
    "    def _get_xgb_from_pipe(pipe):\n",
    "        if not hasattr(pipe, \"named_steps\"):\n",
    "            return None\n",
    "        clf = pipe.named_steps.get(\"clf\", None)\n",
    "        return clf if (clf is not None and hasattr(clf, \"get_booster\")) else None\n",
    "\n",
    "    xgb_est = None\n",
    "    for cand in [\"pipe_xgb\", \"model_best\"]:\n",
    "        if cand in g:\n",
    "            xgb_est = _get_xgb_from_pipe(g[cand])\n",
    "            if xgb_est is not None:\n",
    "                break\n",
    "\n",
    "    if xgb_est is not None:\n",
    "        try:\n",
    "            booster = xgb_est.get_booster()\n",
    "            fscore = booster.get_score(importance_type=\"gain\")\n",
    "            if len(fscore) > 0:\n",
    "                items = sorted(fscore.items(), key=lambda kv: kv[1], reverse=True)[:40]\n",
    "                names = [k for k, _ in items]\n",
    "                gains = [v for _, v in items]\n",
    "                def _map_name(raw):\n",
    "                    if raw.startswith(\"f\") and raw[1:].isdigit():\n",
    "                        idx = int(raw[1:])\n",
    "                        if feature_names is not None and idx < len(feature_names):\n",
    "                            return str(feature_names[idx])\n",
    "                    return raw\n",
    "                names = [_map_name(n) for n in names]\n",
    "                plt.figure(figsize=(8, max(4, len(names) * 0.25)))\n",
    "                plt.barh(range(len(names)), gains[::-1])\n",
    "                plt.yticks(range(len(names)), names[::-1])\n",
    "                plt.xlabel(\"Gain\")\n",
    "                plt.title(\"Feature Importance — XGBoost (gain)\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(FIG_DIR / \"feature_importance_xgb_gain.png\", dpi=200)\n",
    "                plt.close()\n",
    "        except Exception as e:\n",
    "            print(\"[warn] XGB FI export:\", e)\n",
    "\n",
    "print(\"[done] Exported: roc_curve.png, pr_curve.png, calibration_curve.png, confusion_matrix.png, \"\n",
    "      \"feature_importance_lgbm.png (if LGBM), feature_importance_xgb_gain.png (if XGB).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12a64d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] Exported pipeline to data\\models\\model_best.joblib\n"
     ]
    }
   ],
   "source": [
    "# --- Export best pipeline for inference --- #\n",
    "from joblib import dump\n",
    "\n",
    "# Если model_best уже есть — просто сохраняем\n",
    "if \"model_best\" in globals():\n",
    "    try:\n",
    "        dump(model_best, MODELS_DIR / 'model_best.joblib')\n",
    "        print(f\"[done] Exported pipeline to {MODELS_DIR / 'model_best.joblib'}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] Could not export model_best: {e}\")\n",
    "else:\n",
    "    # Попробуем выбрать лучший пайплайн по results_df или взять из доступных кандидатов\n",
    "    candidates = {\n",
    "        \"LogReg\":  globals().get(\"pipe_lr\"),\n",
    "        \"RF_base\": globals().get(\"pipe_rf\"),\n",
    "        \"XGB_es\":  globals().get(\"pipe_xgb\"),\n",
    "        # если у тебя лучший — именно lgb_best как estimator, пайплайна может не быть:\n",
    "        # ниже всё равно попытаемся сохранить любой валидный pipeline\n",
    "    }\n",
    "\n",
    "    chosen = None\n",
    "    if \"results_df\" in globals():\n",
    "        try:\n",
    "            best_row = results_df.sort_values([\"auc\", \"f1\"], ascending=False).iloc[0]\n",
    "            best_name = str(best_row[\"model\"])\n",
    "            # Если лучший входит в candidates и это pipeline — берём его\n",
    "            for key, obj in candidates.items():\n",
    "                if obj is not None and key in best_name:\n",
    "                    chosen = obj\n",
    "                    break\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # если по метрикам не вышло — бери первый доступный из candidates\n",
    "    if chosen is None:\n",
    "        chosen = next((v for v in candidates.values() if v is not None), None)\n",
    "\n",
    "    if chosen is not None:\n",
    "        try:\n",
    "            dump(chosen, MODELS_DIR / 'model_best.joblib')\n",
    "            print(f\"[done] Exported pipeline to {MODELS_DIR / 'model_best.joblib'}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] Could not export chosen pipeline: {e}\")\n",
    "    else:\n",
    "        print(\"[warn] No pipeline object found to export. Define `model_best` or provide a pipeline (pipe_lr/pipe_rf/pipe_xgb).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097880da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] Saved: y_test.npy\n",
      "[done] Saved: y_score.npy (via pipeline:Pipeline )\n",
      "[done] Saved: y_pred_050.npy\n",
      "[done] Saved: test_groups.csv\n",
      "[done] Saved: feature_names.npy\n",
      "[done] Saved: X_test_enc (npz/npy)\n",
      "Export for 03_fairness_and_explainability.ipynb: COMPLETED.\n"
     ]
    }
   ],
   "source": [
    "# --- Export artifacts for 03_fairness_and_explainability.ipynb --- #\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# --- Предпосылки ---\n",
    "if \"X_test\" not in globals() or \"y_test\" not in globals():\n",
    "    raise RuntimeError(\"Нужны X_test и y_test в памяти. Выполни блоки подготовки данных/валидации в 02.\")\n",
    "\n",
    "y_true = np.asarray(y_test)\n",
    "np.save(ART_DIR / \"y_test.npy\", y_true)\n",
    "print(\"[done] Saved: y_test.npy\")\n",
    "\n",
    "g = globals()\n",
    "\n",
    "# --- Кандидаты пайплайнов и эстиматоров ---\n",
    "pipeline_candidates = [\n",
    "    g.get(\"model_best\"),\n",
    "    g.get(\"pipe_xgb\"),\n",
    "    g.get(\"pipe_rf\"),\n",
    "    g.get(\"pipe_lr\"),\n",
    "]\n",
    "estimator_candidates = [\n",
    "    g.get(\"lgb_best\"),\n",
    "    g.get(\"xgb_best\"),\n",
    "    g.get(\"rf_best\"),\n",
    "]\n",
    "\n",
    "def _get_preproc_from_pipe(pipe):\n",
    "    if pipe is None or not hasattr(pipe, \"named_steps\"):\n",
    "        return None\n",
    "    for k in (\"preproc\", \"prep\", \"transformer\", \"ct\"):\n",
    "        if k in pipe.named_steps:\n",
    "            return pipe.named_steps[k]\n",
    "    return None\n",
    "\n",
    "# 1) находим препроцессор в любом доступном пайплайне; иначе берём preprocessor\n",
    "preproc = None\n",
    "for p in pipeline_candidates:\n",
    "    preproc = _get_preproc_from_pipe(p)\n",
    "    if preproc is not None:\n",
    "        break\n",
    "if preproc is None and \"preprocessor\" in g:\n",
    "    preproc = g[\"preprocessor\"]\n",
    "\n",
    "# 2) пытаемся получить XS (encoded X_test) — это не строго обязательно\n",
    "XS = None\n",
    "if preproc is not None:\n",
    "    try:\n",
    "        preproc_fitted = preproc.fit(X_train, y_train)\n",
    "        XS = preproc_fitted.transform(X_test)\n",
    "    except Exception as e:\n",
    "        print(\"[info] Could not build XS via preproc:\", e)\n",
    "\n",
    "# 3) feature names, если доступны\n",
    "feature_names = None\n",
    "if preproc is not None and hasattr(preproc, \"get_feature_names_out\"):\n",
    "    try:\n",
    "        feature_names = preproc.get_feature_names_out()\n",
    "    except Exception:\n",
    "        feature_names = None\n",
    "\n",
    "# --- Хелперы для скоринга ---\n",
    "def _has_proba(m): \n",
    "    return hasattr(m, \"predict_proba\")\n",
    "\n",
    "def _score_with_model(m, X):\n",
    "    try:\n",
    "        if _has_proba(m):\n",
    "            y_score = m.predict_proba(X)[:, 1]\n",
    "        elif hasattr(m, \"decision_function\"):\n",
    "            y_score = m.decision_function(X)\n",
    "        else:\n",
    "            return None, None\n",
    "        y_pred = (y_score >= 0.5).astype(\"int8\")\n",
    "        return y_score, y_pred\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "# --- 4 шага получения y_score / y_pred ---\n",
    "y_score, y_pred = None, None\n",
    "model_used = None\n",
    "\n",
    "# (1) pipeline → X_test\n",
    "for pipe in pipeline_candidates:\n",
    "    if pipe is None:\n",
    "        continue\n",
    "    y_score, y_pred = _score_with_model(pipe, X_test)\n",
    "    if y_score is not None:\n",
    "        model_used = f\"pipeline:{type(pipe).__name__}\"\n",
    "        break\n",
    "\n",
    "# (2) временный Pipeline(preproc + estimator) → X_test\n",
    "if y_score is None and preproc is not None:\n",
    "    for est in estimator_candidates:\n",
    "        if est is None:\n",
    "            continue\n",
    "        tmp_pipe = Pipeline([(\"preproc\", preproc), (\"clf\", est)])\n",
    "        y_score, y_pred = _score_with_model(tmp_pipe, X_test)\n",
    "        if y_score is not None:\n",
    "            model_used = f\"temp_pipe:{type(est).__name__}\"\n",
    "            break\n",
    "\n",
    "# (3) чистый эстиматор → XS\n",
    "if y_score is None and XS is not None:\n",
    "    for est in estimator_candidates:\n",
    "        if est is None:\n",
    "            continue\n",
    "        y_score, y_pred = _score_with_model(est, XS)\n",
    "        if y_score is not None:\n",
    "            model_used = f\"est+XS:{type(est).__name__}\"\n",
    "            break\n",
    "\n",
    "# (4) fallback: переиспользовать прошлый y_score\n",
    "if y_score is None and (ART_DIR / \"y_score.npy\").exists():\n",
    "    try:\n",
    "        y_score = np.load(ART_DIR / \"y_score.npy\")\n",
    "        y_pred = (y_score >= 0.5).astype(\"int8\")\n",
    "        model_used = \"reused:previous_y_score.npy\"\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# --- Экспорт ключевых артефактов для 03 ---\n",
    "if y_score is None:\n",
    "    print(\"[warn] y_score is None — не удалось получить вероятности ни одним способом.\")\n",
    "else:\n",
    "    np.save(ART_DIR / \"y_score.npy\", np.asarray(y_score))\n",
    "    print(\"[done] Saved: y_score.npy\", \"(via\", model_used, \")\")\n",
    "\n",
    "if y_pred is None:\n",
    "    print(\"[warn] y_pred_050 is None — не удалось получить метки (thr=0.5).\")\n",
    "else:\n",
    "    np.save(ART_DIR / \"y_pred_050.npy\", np.asarray(y_pred))\n",
    "    print(\"[done] Saved: y_pred_050.npy\")\n",
    "\n",
    "# --- Группы/защищённые признаки ---\n",
    "cols = [c for c in (\"sex\", \"race\") if c in X_test.columns]\n",
    "df_groups = pd.DataFrame(index=X_test.index)\n",
    "for c in cols:\n",
    "    df_groups[c] = X_test[c]\n",
    "df_groups[\"y_true\"] = y_true\n",
    "df_groups.reset_index(names=\"row_id\", inplace=True)\n",
    "df_groups.to_csv(ART_DIR / \"test_groups.csv\", index=False)\n",
    "print(\"[done] Saved: test_groups.csv\")\n",
    "\n",
    "# --- Необязательно, но полезно: сохранить XS и feature_names ---\n",
    "if feature_names is not None:\n",
    "    try:\n",
    "        np.save(ART_DIR / \"feature_names.npy\", feature_names)\n",
    "        print(\"[done] Saved: feature_names.npy\")\n",
    "    except Exception as e:\n",
    "        print(\"[warn] feature_names save failed:\", e)\n",
    "\n",
    "if XS is not None:\n",
    "    try:\n",
    "        if sp.issparse(XS):\n",
    "            sp.save_npz(ART_DIR / \"X_test_enc.npz\", XS)\n",
    "        else:\n",
    "            np.save(ART_DIR / \"X_test_enc.npy\", XS)\n",
    "        print(\"[done] Saved: X_test_enc (npz/npy)\")\n",
    "    except Exception as e:\n",
    "        print(\"[warn] X_test_enc save failed:\", e)\n",
    "else:\n",
    "    print(\"[info] XS not available; 03 will still work via y_score + test_groups.\")\n",
    "\n",
    "print(\"Export for 03_fairness_and_explainability.ipynb: COMPLETED.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc40e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] Saved: predictions/preds_pipeline.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Export demo predictions (pipeline) --- #\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from paths import ROOT, DATA_DIR, ART_DIR, MODELS_DIR\n",
    "\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PRED_DIR = ROOT / 'predictions'\n",
    "PRED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "g = globals()\n",
    "\n",
    "def _get_preproc_from_pipe(pipe):\n",
    "    if not hasattr(pipe, \"named_steps\"):\n",
    "        return None\n",
    "    for k in (\"preproc\", \"prep\", \"transformer\", \"ct\"):\n",
    "        if k in pipe.named_steps:\n",
    "            return pipe.named_steps[k]\n",
    "    return None\n",
    "\n",
    "def _has_proba(m):\n",
    "    return hasattr(m, \"predict_proba\")\n",
    "\n",
    "def _score_with_model(m, X):\n",
    "    if _has_proba(m):\n",
    "        return m.predict_proba(X)[:, 1]\n",
    "    elif hasattr(m, \"decision_function\"):\n",
    "        return m.decision_function(X)\n",
    "    return None\n",
    "\n",
    "# 1) сначала пытаемся взять готовый pipeline\n",
    "pipe = g.get(\"model_best\") or g.get(\"pipe_xgb\") or g.get(\"pipe_rf\") or g.get(\"pipe_lr\")\n",
    "\n",
    "proba = None\n",
    "if pipe is not None and \"X_test\" in g:\n",
    "    try:\n",
    "        proba = _score_with_model(pipe, X_test)\n",
    "    except Exception as e:\n",
    "        print(\"[info] pipeline scoring failed:\", e)\n",
    "\n",
    "# 2) если пайплайна нет — попробуем собрать временный pipeline из preproc + estimator\n",
    "if proba is None and \"X_test\" in g:\n",
    "    preproc = None\n",
    "    for cand in (g.get(\"model_best\"), g.get(\"pipe_xgb\"), g.get(\"pipe_rf\"), g.get(\"pipe_lr\")):\n",
    "        if cand is not None:\n",
    "            preproc = _get_preproc_from_pipe(cand)\n",
    "            if preproc is not None:\n",
    "                break\n",
    "    if preproc is None and \"preprocessor\" in g:\n",
    "        preproc = g[\"preprocessor\"]\n",
    "\n",
    "    if preproc is not None:\n",
    "        for est in (g.get(\"lgb_best\"), g.get(\"xgb_best\"), g.get(\"rf_best\")):\n",
    "            if est is None:\n",
    "                continue\n",
    "            tmp_pipe = Pipeline([(\"preproc\", preproc), (\"clf\", est)])\n",
    "            try:\n",
    "                proba = _score_with_model(tmp_pipe, X_test)\n",
    "            except Exception:\n",
    "                proba = None \n",
    "            if proba is not None:\n",
    "                break\n",
    "\n",
    "# 3) если вообще ничего не сработало - используем уже сохранённый y_score (если есть)\n",
    "if proba is None and (ART_DIR / \"y_score.npy\").exists():\n",
    "    try:\n",
    "        proba = np.load(ART_DIR / \"y_score.npy\")\n",
    "        print(\"[info] Using previously saved y_score.npy for demo predictions.\")\n",
    "    except Exception:\n",
    "        proba = None\n",
    "\n",
    "if proba is None:\n",
    "    print(\"[warn] Could not export preds_pipeline.csv: no pipeline/estimator with predict_proba/decision_function found.\")\n",
    "else:\n",
    "    label = (proba >= 0.5).astype(\"int8\")\n",
    "    pd.DataFrame({\"proba\": proba, \"label\": label}).to_csv(PRED_DIR / \"preds_pipeline.csv\", index=False)\n",
    "    print(f'[done] Saved: {PRED_DIR / \"preds_pipeline.csv\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a78530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ART_DIR.resolve().parts[-2:] == ('data', 'artifacts'), f'ART_DIR={ART_DIR}'\n",
    "assert MODELS_DIR.resolve().parts[-2:] == ('data', 'models'),   f'MODELS_DIR={MODELS_DIR}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "census_ds2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
