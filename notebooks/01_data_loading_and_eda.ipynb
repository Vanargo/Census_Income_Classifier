{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "© 2025 Vanargo · License: MIT. See the `LICENSE` file in the repository root."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# --- 01. Data loading and EDA --- #\n",
    "\n",
    "Loading, cleaning, exploratory data analysis, and feature engineering for the Adult (Census Income) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports and basyc style --- #\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# unified clean plotting style #\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"figure.figsize\": (8, 4),\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "    }\n",
    ")\n",
    "sns.set_context(\"notebook\")\n",
    "\n",
    "# silence loggers of popular libraries #\n",
    "for name in (\"lightgbm\", \"xgboost\", \"matplotlib\", \"numba\"):\n",
    "    logging.getLogger(name).setLevel(logging.ERROR)\n",
    "\n",
    "# relevant warning filters for this notebook #\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Glyph .* missing from current font.*\")\n",
    "\n",
    "# controlled randomness for reproducibilty #\n",
    "RNG = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Project paths bootstrap --- #\n",
    "\n",
    "import sys\n",
    "\n",
    "# define project root relative to this notebook #\n",
    "ROOT = Path.cwd().resolve().parents[0]\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "REPORTS_DIR = DATA_DIR / \"reports\"\n",
    "\n",
    "# ad project root to sys.path if missing #\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "print(f\"[ok] project root: {ROOT}\")\n",
    "print(f\"[ok] data dir: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Notebook preamble: UX, magics, helpers --- #\n",
    "\n",
    "# IPython magics #\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# display options #\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:,.4f}\")\n",
    "\n",
    "# reproducibility #\n",
    "if \"RNG\" not in globals():\n",
    "    RNG = np.random.default_rng(42)\n",
    "\n",
    "# figures directory for this notebook #\n",
    "FIG_DIR_01 = REPORTS_DIR / \"figures_01\"\n",
    "FIG_DIR_01.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_fig(fig, name: str, dpi: int = 150) -> Path:\n",
    "    \"\"\"\n",
    "    Save matplotlib figure to reports/figures_01 as <name>.png.\n",
    "    \"\"\"\n",
    "    p = FIG_DIR_01 / f\"{name}.png\"\n",
    "    fig.savefig(p, dpi=dpi, bbox_inches=\"tight\")\n",
    "    print(f\"[saved] {p}\")\n",
    "    return p\n",
    "\n",
    "\n",
    "def log_df(df: pd.DataFrame, name: str) -> None:\n",
    "    \"\"\"\n",
    "    Compact dataframe log: shape and column list.\n",
    "    \"\"\"\n",
    "    print(f\"[{name}] shape={df.shape} cols={list(df.columns)}\")\n",
    "\n",
    "\n",
    "# sanity print #\n",
    "print(f\"[env] pandas {pd.__version__} | numpy {np.__version__} | seaborn {sns.__version__}\")\n",
    "print(f\"[figures] {FIG_DIR_01}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loading Adult dataset (train/test) --- #\n",
    "\n",
    "# paths #\n",
    "TRAIN_PATH = RAW_DIR / \"adult.data\"\n",
    "TEST_PATH = RAW_DIR / \"adult.test\"\n",
    "\n",
    "# column names from UCI documentation #\n",
    "COLS = [\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education_num\",\n",
    "    \"marital_status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "    \"native_country\",\n",
    "    \"income\",\n",
    "]\n",
    "\n",
    "# common reading parameters #\n",
    "READ_OPTS = dict(\n",
    "    names=COLS,\n",
    "    na_values=[\"?\", \" ?\"],\n",
    "    skipinitialspace=True,\n",
    "    # read as strings, then cast types explicitly\n",
    "    dtype=str,\n",
    ")\n",
    "\n",
    "# train #\n",
    "df_train = pd.read_csv(TRAIN_PATH, **READ_OPTS)\n",
    "df_train[\"source\"] = \"train\"\n",
    "\n",
    "# test (the first line in the file is a header, skip it) #\n",
    "df_test = pd.read_csv(TEST_PATH, **READ_OPTS, skiprows=1)\n",
    "df_test[\"source\"] = \"test\"\n",
    "\n",
    "# merge #\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "# strip spaces and clean target values #\n",
    "df = df.apply(lambda c: c.str.strip() if c.dtype == \"object\" else c)\n",
    "df[\"income\"] = df[\"income\"].replace({\"<=50K.\": \"<=50K\", \">50K.\": \">50K\"})\n",
    "\n",
    "# explicit type casting for numeric features #\n",
    "NUMERIC_COLS = [\"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]\n",
    "for c in NUMERIC_COLS:\n",
    "    # NaN if garbage\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# logging and preview #\n",
    "log_df(df, \"adult_full\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initial overview --- #\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "obj_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "if num_cols:\n",
    "    display(df[num_cols].describe(percentiles=[0.05, 0.25, 0.5, 0.75, 0.95]).T)\n",
    "else:\n",
    "    print(\"[info] numeric columns not found\")\n",
    "\n",
    "if obj_cols:\n",
    "    display(df[obj_cols].describe().T)\n",
    "else:\n",
    "    print(\"[info] object/category columns not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Distributions of numeric features --- #\n",
    "\n",
    "num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "print(f\"[ok] numeric columns: {len(num_cols)}\")\n",
    "\n",
    "if not num_cols:\n",
    "    print(\"[warn] numeric columns not found\")\n",
    "else:\n",
    "    # individual histograms #\n",
    "    for col in num_cols:\n",
    "        fig, ax = plt.subplots(figsize=(6, 3))\n",
    "        sns.histplot(data=df, x=col, kde=True, bins=30, ax=ax, color=\"steelblue\")\n",
    "        ax.set_title(f\"Distribution of {col}\")\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        save_fig(fig, f\"hist_{col}\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    # combined grid plot #\n",
    "    ncols = 3\n",
    "    nrows = int(np.ceil(len(num_cols) / ncols))\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols * 4, nrows * 3))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, col in enumerate(num_cols):\n",
    "        sns.histplot(data=df, x=col, kde=True, bins=30, ax=axes[i], color=\"steelblue\")\n",
    "        axes[i].set_title(col)\n",
    "        axes[i].grid(alpha=0.3)\n",
    "\n",
    "    # turn off unused axes #\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_fig(fig, \"hist_numeric_all\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Correlation between numeric features --- #\n",
    "\n",
    "num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "if not num_cols:\n",
    "    print(\"[warn] numeric columns not found, correlation skipped\")\n",
    "else:\n",
    "    corr = df[num_cols].corr(method=\"pearson\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    sns.heatmap(\n",
    "        corr,\n",
    "        cmap=\"vlag\",\n",
    "        center=0,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        linewidths=0.5,\n",
    "        cbar_kws={\"shrink\": 0.8},\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(\"Correlation between numeric features (Pearson)\")\n",
    "    plt.tight_layout()\n",
    "    save_fig(fig, \"corr_numeric\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    display(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Associations between categorical features (Cramér’s V) --- #\n",
    "\n",
    "\n",
    "cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "\n",
    "def cramers_v(x: pd.Series, y: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Computes Cramér’s V for two categorical features.\n",
    "    \"\"\"\n",
    "    tbl = pd.crosstab(x, y, dropna=False)\n",
    "    chi2, _, _, _ = chi2_contingency(tbl, correction=False)\n",
    "    n = tbl.values.sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = tbl.shape\n",
    "    phi2corr = max(0, phi2 - (k - 1) * (r - 1) / (n - 1))\n",
    "    rcorr = r - (r - 1) ** 2 / (n - 1)\n",
    "    kcorr = k - (k - 1) ** 2 / (n - 1)\n",
    "    return np.sqrt(phi2corr / min((kcorr - 1), (rcorr - 1)))\n",
    "\n",
    "\n",
    "if len(cat_cols) < 2:\n",
    "    print(\"[info] not enough categorical features for Cramér’s V matrix\")\n",
    "else:\n",
    "    # Cramér’s V matrix #\n",
    "    cramers_mat = pd.DataFrame(\n",
    "        np.zeros((len(cat_cols), len(cat_cols))), index=cat_cols, columns=cat_cols\n",
    "    )\n",
    "\n",
    "    for i, col1 in enumerate(cat_cols):\n",
    "        for j, col2 in enumerate(cat_cols):\n",
    "            if i >= j:\n",
    "                continue\n",
    "            v = cramers_v(df[col1], df[col2])\n",
    "            cramers_mat.loc[col1, col2] = cramers_mat.loc[col2, col1] = v\n",
    "\n",
    "    # visualization #\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(\n",
    "        cramers_mat,\n",
    "        cmap=\"crest\",\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        square=True,\n",
    "        cbar_kws={\"shrink\": 0.7},\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(\"Cramér’s V between categorical features\")\n",
    "    plt.tight_layout()\n",
    "    save_fig(fig, \"cramers_v_matrix\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    display(cramers_mat.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Distributions of categorical features --- #\n",
    "\n",
    "cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "print(f\"[ok] categorical columns: {len(cat_cols)}\")\n",
    "\n",
    "if not cat_cols:\n",
    "    print(\"[warn] no categorical columns found\")\n",
    "else:\n",
    "    for col in cat_cols:\n",
    "        # if cardinality is high, plot on top-20 values #\n",
    "        n_unique = df[col].nunique(dropna=True)\n",
    "        if n_unique > 20:\n",
    "            top_vals = df[col].value_counts(dropna=False).head(20).sort_values(ascending=False)\n",
    "            data_plot = pd.DataFrame({\"value\": top_vals.index, \"count\": top_vals.values})\n",
    "            title = f\"{col} (top 20 из {n_unique})\"\n",
    "        else:\n",
    "            data_plot = df[[col]].copy()\n",
    "            title = col\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(7, 3))\n",
    "        sns.countplot(\n",
    "            data=data_plot, x=col if n_unique <= 20 else \"value\", ax=ax, color=\"steelblue\"\n",
    "        )\n",
    "        ax.set_title(f\"Distribution: {title}\")\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.tick_params(axis=\"x\", rotation=45)\n",
    "        ax.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        save_fig(fig, f\"bar_{col}\")\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Categorical features vs target variable (income) --- #\n",
    "\n",
    "target_col = \"income\"\n",
    "cat_cols = [c for c in df.select_dtypes(include=[\"object\", \"category\"]).columns if c != target_col]\n",
    "\n",
    "if target_col not in df.columns:\n",
    "    print(f'[warn] target \"{target_col}\" not found')\n",
    "elif not cat_cols:\n",
    "    print(\"[warn] no categorical columns found\")\n",
    "else:\n",
    "    for col in cat_cols:\n",
    "        n_unique = df[col].nunique(dropna=True)\n",
    "        if n_unique > 20:\n",
    "            print(f\"[skip] {col}: {n_unique} unique values\")\n",
    "            continue\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(7, 3))\n",
    "        sns.countplot(data=df, x=col, hue=target_col, ax=ax, palette=\"Set2\")\n",
    "        ax.set_title(f\"{col} vs {target_col}\")\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.tick_params(axis=\"x\", rotation=45)\n",
    "        ax.legend(title=target_col, loc=\"upper right\")\n",
    "        ax.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        save_fig(fig, f\"bar_{col}_vs_{target_col}\")\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Numerical features vs target variable (income) --- #\n",
    "\n",
    "target_col = \"income\"\n",
    "num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "if target_col not in df.columns:\n",
    "    print(f'[warn] target \"{target_col}\" not found')\n",
    "elif not num_cols:\n",
    "    print(\"[warn] numeric columns not found\")\n",
    "else:\n",
    "    for col in num_cols:\n",
    "        fig, ax = plt.subplots(figsize=(6, 3))\n",
    "        sns.boxplot(\n",
    "            data=df,\n",
    "            x=target_col,\n",
    "            y=col,\n",
    "            hue=target_col,  # fix for FutureWarning\n",
    "            legend=False,  # disable legend (it duplicates labels)\n",
    "            palette=\"Set2\",\n",
    "            showfliers=False,\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.set_title(f\"{col} vs {target_col}\")\n",
    "        ax.set_xlabel(target_col)\n",
    "        ax.set_ylabel(col)\n",
    "        ax.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        save_fig(fig, f\"box_{col}_vs_{target_col}\")\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Missing values analysis --- #\n",
    "\n",
    "# count missing values #\n",
    "na_stats = df.isna().sum()\n",
    "na_stats = na_stats[na_stats > 0].sort_values(ascending=False)\n",
    "\n",
    "if na_stats.empty:\n",
    "    print(\"[ok] no missing values detected.\")\n",
    "else:\n",
    "    na_df = pd.DataFrame(\n",
    "        {\"missing_count\": na_stats, \"missing_pct\": (na_stats / len(df) * 100).round(2)}\n",
    "    )\n",
    "    display(na_df)\n",
    "\n",
    "    # visualization #\n",
    "    fig, ax = plt.subplots(figsize=(7, 3))\n",
    "    sns.barplot(data=na_df.reset_index(), x=\"index\", y=\"missing_pct\", color=\"steelblue\", ax=ax)\n",
    "    ax.set_title(\"Percentage of missing values by feature (%)\")\n",
    "    ax.set_xlabel(\"Feature\")\n",
    "    ax.set_ylabel(\"Missing (%)\")\n",
    "    ax.tick_params(axis=\"x\", rotation=45)\n",
    "    ax.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    save_fig(fig, \"missing_values\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Outliers by IQR and binary flags --- #\n",
    "\n",
    "NUM_COLS = df.select_dtypes(include=np.number).columns.tolist()\n",
    "OUTLIER_PREFIX = \"is_outlier_\"\n",
    "\n",
    "\n",
    "def iqr_flags(s: pd.Series, k: float = 1.5) -> pd.Series:\n",
    "    \"\"\"Return 0/1 outlier flag based on the IQR rule.\"\"\"\n",
    "    q1 = s.quantile(0.25)\n",
    "    q3 = s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    if not np.isfinite(iqr) or iqr == 0:\n",
    "        return pd.Series(np.zeros(len(s), dtype=int), index=s.index)\n",
    "    lo, hi = q1 - k * iqr, q3 + k * iqr\n",
    "    return ((s < lo) | (s > hi)).astype(int)\n",
    "\n",
    "\n",
    "if not NUM_COLS:\n",
    "    print(\"[warn] numeric columns not found, outlier flags skipped\")\n",
    "else:\n",
    "    for c in NUM_COLS:\n",
    "        flag_col = f\"{OUTLIER_PREFIX}{c}\"\n",
    "        df[flag_col] = iqr_flags(df[c])\n",
    "\n",
    "    # brief summary of outlier share #\n",
    "    flag_cols = [c for c in df.columns if c.startswith(OUTLIER_PREFIX)]\n",
    "    outlier_share = (df[flag_cols].sum().sort_values(ascending=False) / len(df)).round(4)\n",
    "    display(outlier_share.to_frame(\"share\"))\n",
    "    print(f\"[ok] flags added: {len(flag_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom feature (feature engineering) --- #\n",
    "\n",
    "\n",
    "def add_custom_features(dfin: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_ = dfin.copy()\n",
    "\n",
    "    # net capital #\n",
    "    if {\"capital_gain\", \"capital_loss\"}.issubset(df_.columns):\n",
    "        df_[\"capital_net\"] = (df_[\"capital_gain\"].fillna(0) - df_[\"capital_loss\"].fillna(0)).astype(\n",
    "            float\n",
    "        )\n",
    "    else:\n",
    "        df_[\"capital_net\"] = np.nan\n",
    "\n",
    "    # useful ratios #\n",
    "    if {\"hours_per_week\", \"education_num\"}.issubset(df_.columns):\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            df_[\"hours_per_edu\"] = df_[\"hours_per_week\"].astype(float) / df_[\n",
    "                \"education_num\"\n",
    "            ].replace(0, np.nan).astype(float)\n",
    "\n",
    "    # non-zero capital indicator #\n",
    "    if \"capital_net\" in df_.columns:\n",
    "        df_[\"has_capital\"] = (df_[\"capital_net\"].fillna(0) != 0).astype(int)\n",
    "\n",
    "    return df_\n",
    "\n",
    "\n",
    "df = add_custom_features(df)\n",
    "log_df(df, \"adult_with_custom_features\")\n",
    "\n",
    "# quick preview #\n",
    "df[\n",
    "    [\n",
    "        \"capital_gain\",\n",
    "        \"capital_loss\",\n",
    "        \"capital_net\",\n",
    "        \"hours_per_week\",\n",
    "        \"education_num\",\n",
    "        \"hours_per_edu\",\n",
    "        \"has_capital\",\n",
    "    ]\n",
    "].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Age binning (age_group) --- #\n",
    "\n",
    "if \"age\" not in df.columns:\n",
    "    print('[warn] \"age\" not in columns, age_group skipped')\n",
    "else:\n",
    "    bins = [0, 24, 34, 44, 54, 64, np.inf]\n",
    "    labels = [\"18–24\", \"25–34\", \"35–44\", \"45–54\", \"55–64\", \"65+\"]\n",
    "    df[\"age_group\"] = pd.cut(df[\"age\"], bins=bins, labels=labels, right=True, include_lowest=True)\n",
    "    df[\"age_group\"] = df[\"age_group\"].astype(\"category\")\n",
    "    print(\"[ok] age_group created\")\n",
    "\n",
    "# Export EDA dataset #\n",
    "\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "p_parquet = PROCESSED_DIR / \"adult_eda.parquet\"\n",
    "p_csv = PROCESSED_DIR / \"adult_eda.csv\"\n",
    "\n",
    "# export #\n",
    "df.to_parquet(p_parquet, index=False)\n",
    "df.to_csv(p_csv, index=False)\n",
    "\n",
    "print(f\"[saved] {p_parquet}\")\n",
    "print(f\"[saved] {p_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Export of key figures (control check) --- #\n",
    "\n",
    "expected = [\n",
    "    \"hist_numeric_all.png\",\n",
    "    \"corr_numeric.png\",\n",
    "    \"cramers_v_matrix.png\",\n",
    "    \"missing_values.png\",\n",
    "]\n",
    "# plus individual ones: hist_*, bar_*, box_* - already saved in previous cells #\n",
    "\n",
    "missing = [name for name in expected if not (FIG_DIR_01 / name).exists()]\n",
    "if missing:\n",
    "    print(\"[warn] missing figures:\", missing)\n",
    "else:\n",
    "    print(\"[ok] key figures present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# --- Final EDA Summary ---\n",
    "\n",
    "**Data quality:**\n",
    "1. Missing values are concentrated in three features: `workclass`, `occupation`, `native_country` (see `missing_values.png`). Other fields are complete.\n",
    "2. Categorical values are standardized; rare categories are mostly found in `native_country`. This is relevant for grouping into “Other” before modeling.\n",
    "3. No explicit duplicates by key fields were detected in the current review.\n",
    "4. The target variable is imbalanced: `>50k` occurs significantly less often than `<=50k` (see `bar_income.png`). Stratification and baseline control will be required for metric evaluation.\n",
    "\n",
    "**Basic distributions of numeric features:**\n",
    "1. Age: right-skewed, concentrated between 25–45; higher-income individuals are more frequent in the 35–55 range (see `hist_age.png` and `box_age_vs_income.png`).\n",
    "2. `hours-per-week`: modal region around 40 hours, “heavy tails” for overtime; median higher for the `>50k` group (see `hist_hours_per_week.png`, `box_hours_per_week_vs_income.png`).\n",
    "3. `education_num`: monotonically increasing relationship with income; higher values typical for `>50k` (see `hist_education_num.png`, `box_education_num_vs_income.png`).\n",
    "4. `capital_gain` and `capital_loss`: extremely sparse, dominated by zeros with rare large values; non-zero values are strongly associated with `>50k` (see `hist_capital_gain.png`, `hist_capital_loss.png`, `box_capital_gain_vs_income.png`, `box_capital_loss_vs_income.png`).\n",
    "5. `fnlwgt`: broad distribution with no clearly interpretable relationship to income (see `hist_fnlwgt.png`, `box_fnlwgt_vs_income.png`).\n",
    "6. Numeric correlations are generally low but noticeable for `education_num`, `hours-per-week`, and presence of `capital_gain` (see `corr_numeric.png`).\n",
    "\n",
    "**Categorical features: profile and relationship with income:**\n",
    "1. Education: bachelor’s degree and above more common for `>50k`; lower and middle education levels dominate `<=50k` (see `bar_education.png`, `bar_education_vs_income.png`).\n",
    "2. Marital status: `Married-civ-spouse` dominates among `>50k`; `Never-married` and `Divorced` dominate `<=50k` (see `bar_marital_status.png`, `bar_marital_status_vs_income.png`).\n",
    "3. Household role (`relationship`): categories linked to being a spouse or household head are more frequent in `>50k` (see `bar_relationship.png`, `bar_relationship_vs_income.png`).\n",
    "4. Occupation: `Exec-managerial`, `Prof-specialty`, partly `Tech-support` and `Sales` show higher shares of `>50k`; `Handlers-cleaners`, `Other-service`, and `Machine-op-inspct` dominate `<=50k` (see `bar_occupation.png`, `bar_occupation_vs_income.png`).\n",
    "5. Sex: men more often in `>50k`, women in `<=50k` (see `bar_sex.png`, `bar_sex_vs_income.png`).\n",
    "6. Race: income differences exist but are smaller compared to education, marital status, or occupation (see `bar_race.png`, `bar_race_vs_income.png`).\n",
    "7. `workclass`: private and government sectors show higher `>50k` proportions, while `Without-pay`/`Never-worked` are almost always `<=50k` (see `bar_workclass.png`, `bar_workclass_vs_income.png`).\n",
    "8. `native-country`: U.S. dominates the dataset; several countries have small samples, limiting statistical interpretation (see `bar_native_country.png`).\n",
    "9. `source`: distributions align with expectations from the train/test split (see `bar_source.png`).\n",
    "\n",
    "**Feature associations:**\n",
    "1. The Cramér’s V matrix shows clear relationships: `marital_status <-> relationship`, and clusters of employment features `occupation <-> workclass` with ties to education level (see `cramers_v_matrix.png`). This indicates partial redundancy and potential multicollinearity after one-hot encoding.\n",
    "2. For numeric features, strong linear correlations are absent, reducing collinearity risk in linear models (see `corr_numeric.png`).\n",
    "\n",
    "**Key predictors and effect direction:**\n",
    "1. Most informative predictors for `>50k`: nonzero `capital_gain`, high `education_num`, occupations `Exec-managerial`/`Prof-specialty`, marital status `Married-civ-spouse`, and higher `hours-per-week`.\n",
    "2. Moderately informative: `sex` (male), certain `workclass` and `relationship` categories.\n",
    "3. Weak or ambiguous: `fnlwgt` and long tails of `capital-loss` with unstable effect.\n",
    "4. Age effect is nonlinear: probability of `>50k` rises until mid-age, then stabilizes or plateaus (see `hist_age.png`, `box_age_vs_income.png`).\n",
    "\n",
    "**Modeling implications:**\n",
    "1. Missing values in `workclass`/`occupation`/`native_country` must be handled, and rare categories (especially in `native-country`) aggregated for stable estimates.\n",
    "2. Target imbalance requires stratified validation and metrics robust to skew.\n",
    "3. High sparsity of `capital_gain`/`capital_loss` suggests binary indicators for presence and possible log-transform for nonzero values.\n",
    "4. Categorical clusters (`occupation`–`workclass`–`education`) call for regularization and control of one-hot width; tree-based and boosting models can naturally capture nonlinearities and interactions.\n",
    "5. `fnlwgt` appears weakly informative and can likely be dropped without performance loss.\n",
    "\n",
    "**Conclusions:**\n",
    "1. Income `>50k` is primarily associated with human capital and employment profile: education, occupation type, marital status, working hours, and presence of investment income (`capital_gain`).\n",
    "2. Gender and some demographic factors play a role but are secondary to education, profession, and workload.\n",
    "3. Data quality is sufficient for modeling after targeted handling of missing values and rare categories; models capable of nonlinear and sparse signal capture are expected to perform best."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "census_ds2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
